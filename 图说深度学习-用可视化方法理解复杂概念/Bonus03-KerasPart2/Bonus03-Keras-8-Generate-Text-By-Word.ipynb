{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <small>\n",
    "Copyright (c) 2017-21 Andrew Glassner\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "</small>\n",
    "\n",
    "\n",
    "\n",
    "# Deep Learning: A Visual Approach\n",
    "## by Andrew Glassner, https://glassner.com\n",
    "### Order: https://nostarch.com/deep-learning-visual-approach\n",
    "### GitHub: https://github.com/blueberrymusic\n",
    "------\n",
    "\n",
    "### What's in this notebook\n",
    "\n",
    "This notebook is provided to help you work with Keras and TensorFlow. It accompanies the bonus chapters for my book. The code is in Python3, using the versions of libraries as of April 2021.\n",
    "\n",
    "Note that I've included the output cells in this saved notebook, but Jupyter doesn't save the variables or data that were used to generate them. To recreate any cell's output, evaluate all the cells from the start up to that cell. A convenient way to experiment is to first choose \"Restart & Run All\" from the Kernel menu, so that everything's been defined and is up to date. Then you can experiment using the variables, data, functions, and other stuff defined in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Chapter 3 - Notebook 8: Generate text word by word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Keras steps are a modified version of the character-based RNN at\n",
    "https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py\n",
    "\n",
    "A lot of the word extraction and tokenizing was freely adapted from\n",
    "http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/\n",
    "\n",
    "The Sherlock Holmes text is from Project Gutenberg\n",
    "https://www.gutenberg.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.layers import LSTM, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "import nltk.data\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround for Keras issues on Mac computers (you can comment this\n",
    "# out if you're not on a Mac, or not having problems)\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Make a File_Helper for saving and loading files.\n",
    "\n",
    "save_files = True\n",
    "\n",
    "import os, sys, inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "sys.path.insert(0, os.path.dirname(current_dir)) # path to parent dir\n",
    "from DLBasics_Utilities import File_Helper\n",
    "file_helper = File_Helper(save_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/local/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the stuff we need from the Natural Language Toolkit (NLTK)\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global parameters\n",
    "\n",
    "Of the following parameters,\n",
    "the most important is probably the number of epochs, `Num_epochs`.\n",
    "\n",
    "The more epochs you train for, the better the results. \n",
    "I've found that 500 is a good starting point,\n",
    "but depending on your computer, memory, and GPU (if you have one), that\n",
    "could take hours, or days, or even longer! \n",
    "On my late 2014 iMac (which has a GPU, but not\n",
    "one that TensorFlow can use), each epoch takes about 30 minutes,\n",
    "so 500 epochs would take a little more than 10 days!\n",
    "I ran that once a long time ago, but I'm not going to do it again now.\n",
    "\n",
    "Here I've set `Num_epochs` to 4 epochs just\n",
    "for demonstration purposes, \n",
    "but the output at that point isn't much to\n",
    "celebrate. You'll surely be able to crank that up if you\n",
    "have a more modern computer with a GPU,\n",
    "or you use a cloud service such as Colab (which \n",
    "offers free processing on their GPU-enabled systems)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "\n",
    "Vocabulary_size = 8000\n",
    "Batch_size = 64  # Set to 1 below if we're stateful\n",
    "Learning_rate = 0.01\n",
    "\n",
    "\n",
    "Num_epochs = 4\n",
    "Start_epoch = 1\n",
    "input_dir = file_helper.get_input_data_dir()\n",
    "Source_text_file = input_dir+'/holmes.txt'\n",
    "output_dir = file_helper.get_saved_output_dir()\n",
    "file_helper.check_for_directory(output_dir)\n",
    "Output_file = output_dir+'/generated-holmes.txt'\n",
    "\n",
    "Window_size = 40\n",
    "Window_step = 3\n",
    "Generated_text_length = 600\n",
    "Random_seed = 42\n",
    "Cells_per_layer = [8, 8]\n",
    "Use_dropout = [True] * len(Cells_per_layer)\n",
    "Dropout_rate = [0.3] * len(Cells_per_layer)\n",
    "Stateful_model = True  \n",
    "File_writer = None\n",
    "Model_name = 'Layers-'+str(Cells_per_layer)+'-stateful-'+str(Stateful_model)\n",
    "\n",
    "if Stateful_model:\n",
    "    Batch_size = 1             # so we can predict with just 1, probably better to modify predictions\n",
    "    Window_step = Window_size  # samples are sequential, not overlapping\n",
    "\n",
    "Unknown_token = \"GLORP\"  # all words not in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  16720  sentences\n"
     ]
    }
   ],
   "source": [
    "# read in text one sentence at a time: https://stackoverflow.com/questions/4576077/python-split-text-on-sentences\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "fp = open(Source_text_file)\n",
    "data = fp.read()\n",
    "tokenized_sentences = tokenizer.tokenize(data)\n",
    "\n",
    "# remove punctuation https://stackoverflow.com/questions/23317458/how-to-remove-punctuation\n",
    "punctuations = [\n",
    "    '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', \n",
    "    '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', \n",
    "    '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', \n",
    "    '~', \"''\",\"`\",\"\\\"\", \",\", \"-\", \"\\n\", \"\\r\", \"‚Äù\"\n",
    "    ]\n",
    "sentences = []\n",
    "for sentence in tokenized_sentences:\n",
    "    no_punc = \" \".join(\"\".join([\" \"+ch+\" \" if ch in punctuations else ch for ch in sentence]).split())\n",
    "    sentences.append(no_punc)\n",
    "    \n",
    "print(\"found \",len(sentences),\" sentences\")\n",
    "\n",
    "# sentences is an array of strings. Each string is what the tokenizer decided made\n",
    "# up an English-language \"sentence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the text contains  366463  words\n"
     ]
    }
   ],
   "source": [
    "text_as_words = []\n",
    "for s in sentences:\n",
    "    words = s.split()\n",
    "    for w in words:\n",
    "        text_as_words.append(w)\n",
    "print(\"the text contains \",len(text_as_words),\" words\")\n",
    "# text_as_words is all the words in the text after tokenizing and removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found  7999  distinct words\n"
     ]
    }
   ],
   "source": [
    "# Count the word frequencies\n",
    "word_freq = nltk.FreqDist(text_as_words)\n",
    "number_of_unique_tokens = 1 + len(word_freq.items())  # add 1 for the \"unknown_token\"\n",
    "\n",
    "# Get the most common words \n",
    "vocab = word_freq.most_common(Vocabulary_size-1)\n",
    "print(\"Found \",len(vocab),\" distinct words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique vocabulary words being used: 8000\n"
     ]
    }
   ],
   "source": [
    "# build index_to_word and word_to_index dictionaries\n",
    "unique_words = [v[0] for v in vocab]\n",
    "unique_words.append(Unknown_token)\n",
    "unique_words = sorted(list(set(unique_words)))\n",
    "print('number of unique vocabulary words being used:', len(unique_words))\n",
    "word_to_index = dict((w, i) for i, w in enumerate(unique_words))\n",
    "index_to_word = dict((i, w) for i, w in enumerate(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using vocabulary size 8000.\n",
      "word popularity 0: <,> used 22050 times\n",
      "word popularity 1: <.> used 18394 times\n",
      "word popularity 2: <the> used 15607 times\n",
      "word popularity 3: <and> used 7915 times\n",
      "word popularity 4: <of> used 7622 times\n",
      "word popularity 5: <I> used 7614 times\n",
      "word popularity 6: <to> used 7566 times\n",
      "word popularity 7: <a> used 7083 times\n",
      "word popularity 8: <that> used 5135 times\n",
      "word popularity 9: <\"> used 5093 times\n"
     ]
    }
   ],
   "source": [
    "print('Using vocabulary size %d.' % Vocabulary_size)\n",
    "for i in range(10):\n",
    "    print(\"word popularity \"+str(i)+\": <\"+vocab[i][0]+\"> used \"+str(vocab[i][1])+\" times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all words not in our vocabulary with the unknown token\n",
    "for i in range(len(text_as_words)):\n",
    "    if not text_as_words[i] in word_to_index:\n",
    "        text_as_words[i] = Unknown_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of fragments created: 9161\n"
     ]
    }
   ],
   "source": [
    "# make huge list of windowed fragments\n",
    "fragments = []\n",
    "next_words = []\n",
    "for i in range(0, len(text_as_words) - Window_size, Window_step):\n",
    "    fragments.append(text_as_words[i: i + Window_size])\n",
    "    next_words.append(text_as_words[i + Window_size])\n",
    "print('number of fragments created:', len(fragments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip the fragments so it's a multiple of the batch size\n",
    "keep_fragments = 64 * int(len(fragments)/64.)\n",
    "fragments = fragments[0:keep_fragments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "   X.shape =  (9152, 40, 8000)\n",
      "   y.shape =  (9152, 8000)\n"
     ]
    }
   ],
   "source": [
    "# Create the training data\n",
    "# X is a boolean array that is number-of-fragments * Window_size * vocabulary_size\n",
    "#    That is, every fragment contains Window_size entries, one for each word\n",
    "#    Each word is given by a one-hot encoding whose length is the total number of word tkens\n",
    "# y is a boolean array that is number-of-fragments * vocabulary_size\n",
    "#    Each entry is the one-hot encoding of the word that follows the corresponding fragment\n",
    "\n",
    "X = np.zeros((len(fragments), Window_size, Vocabulary_size), dtype=bool)\n",
    "y = np.zeros((len(fragments), Vocabulary_size), dtype=bool)\n",
    "for i, fragment in enumerate(fragments):\n",
    "    for t, word in enumerate(fragment):   \n",
    "        X[i, t, word_to_index[word]] = 1\n",
    "    y[i, word_to_index[next_words[i]]] = 1\n",
    "print(\"Training data:\")\n",
    "print(\"   X.shape = \",X.shape)\n",
    "print(\"   y.shape = \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    # layer 1 is special\n",
    "    if Stateful_model:\n",
    "        if Batch_size != 1:\n",
    "            print(\"*** WARNING! *** build_stateful_model: Batch_size should be 1\")\n",
    "        model.add(LSTM(Cells_per_layer[0], return_sequences=len(Cells_per_layer)>1,\n",
    "                           stateful=True,\n",
    "                           batch_input_shape=(1, Window_size, Vocabulary_size)))\n",
    "    else:\n",
    "        model.add(LSTM(Cells_per_layer[0], return_sequences=True,\n",
    "                       input_shape=(Window_size, Vocabulary_size)))\n",
    "    if Use_dropout[0]:\n",
    "        model.add(Dropout(Dropout_rate[0]))\n",
    "    for i in range(1, len(Cells_per_layer)):\n",
    "        return_sequence = i<len(Cells_per_layer)-1\n",
    "        model.add(LSTM(Cells_per_layer[i], return_sequences=return_sequence))\n",
    "        if Use_dropout:\n",
    "            model.add(Dropout(Dropout_rate[i]))\n",
    "    model.add(Dense(Vocabulary_size))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    #optimizer = RMSprop(lr=Learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = preds[0:len(word_to_index)]\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_string(out_str=''):\n",
    "    print(out_str, end='')\n",
    "    File_writer.write(out_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_report():\n",
    "    print_string(\"Vocabulary_size = \"+str(Vocabulary_size)+\"\\n\")\n",
    "    print_string(\"Batch_size = \"+str(Batch_size)+\"\\n\")\n",
    "    print_string(\"Learning_rate = \"+str(Learning_rate)+\"\\n\")\n",
    "    print_string(\"Source_text_file = \"+str(Source_text_file)+\"\\n\")\n",
    "    print_string(\"Window_size = \"+str(Window_size)+\"\\n\")\n",
    "    print_string(\"Window_step = \"+str(Window_step)+\"\\n\")\n",
    "    print_string(\"Batch_size = \"+str(Batch_size)+\"\\n\")\n",
    "    print_string(\"Num_epochs = \"+str(Num_epochs)+\"\\n\")\n",
    "    print_string(\"Generated_text_length = \"+str(Generated_text_length)+\"\\n\\n\")\n",
    "\n",
    "    print_string(\"Input text file: \"+Source_text_file+'\\n')\n",
    "    print_string(\"    output file: \"+Output_file+'\\n\\n')\n",
    "    print_string(\"full text: \"+str(len(sentences))+\" sentences\\n\")\n",
    "    print_string(\"           \"+str(len(text_as_words))+\" tokens\\n\\n\")\n",
    "    print_string(\"           \"+str(number_of_unique_tokens)+\" unique tokens in source\\n\")\n",
    "    print_string(\"           \"+str(len(unique_words))+\" unique words (tokens) being used\\n\")\n",
    "    print_string('number of fragments created: '+str(len(fragments))+'\\n')\n",
    "    print_string('    resulting in '+str(len(fragments)/64.0)+' batches\\n\\n')\n",
    "    \n",
    "    print_string('Model_name: '+Model_name+'\\n')\n",
    "    print_string('Stateful_model: '+str(Stateful_model)+'\\n')\n",
    "    print_string('Cells per layer: '+str(Cells_per_layer)+'\\n')\n",
    "    print_string('Use dropout: '+str(Use_dropout)+'\\n')\n",
    "    print_string('Dropout rate: '+str(Dropout_rate)+'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (1, 40, 8)                256288    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (1, 40, 8)                0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (1, 8)                    544       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (1, 8)                    0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (1, 8000)                 72000     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (1, 8000)                 0         \n",
      "=================================================================\n",
      "Total params: 328,832\n",
      "Trainable params: 328,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary_size = 8000\n",
      "Batch_size = 1\n",
      "Learning_rate = 0.01\n",
      "Source_text_file = input_data/holmes.txt\n",
      "Window_size = 40\n",
      "Window_step = 40\n",
      "Batch_size = 1\n",
      "Num_epochs = 4\n",
      "Generated_text_length = 600\n",
      "\n",
      "Input text file: input_data/holmes.txt\n",
      "    output file: saved_output/generated-holmes.txt\n",
      "\n",
      "full text: 16720 sentences\n",
      "           366463 tokens\n",
      "\n",
      "           15099 unique tokens in source\n",
      "           8000 unique words (tokens) being used\n",
      "number of fragments created: 9152\n",
      "    resulting in 143.0 batches\n",
      "\n",
      "Model_name: Layers-[8, 8]-stateful-True\n",
      "Stateful_model: True\n",
      "Cells per layer: [8, 8]\n",
      "Use dropout: [True, True]\n",
      "Dropout rate: [0.3, 0.3]\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Iteration 1\n",
      "9152/9152 [==============================] - 561s 60ms/step - loss: 7.0588\n",
      "Loss from iteration 1 = [6.781720161437988]\n",
      "saving model to file  Layers-[8, 8]-stateful-True-epoch-1\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \". It was a terrible household that Black Peter Carey had made for himself , and it was with a sense of relief that we found ourselves in the sunlight again and making our way along a path which had\"\n",
      "----\n",
      ". It was a terrible household that Black Peter Carey had made for himself , and it was with a sense of relief that we found ourselves in the sunlight again and making our way along a path which had upon , my for and man she in I the who , by the has not across the was of In the door , I that GLORP to the , - I feet he to of of , me , to of a is . the my , . the GLORP to had were it . to . Watson the but , the had , was . . , , that of . He , from the , me a . his France . is in , my a you means ? , , was , and and the , - , the matter . . you the story the the I - of . the . They a GLORP , is . , I . The the , had . . . heart that that . was all a the . blooded I you He GLORP you his GLORP . that so . , a the come , . that . her GLORP GLORP in I , off had , I and . this not will and upon that to was the There down , . GLORP . of to to away . now and of those - to GLORP , for No , was . , to . point This , none is . GLORP you a the I with , the of that GLORP , was you . the the looked . the to had have I the was - is and ring Mr extraordinary allowed , , in this , , the then and hand . . for The and , , , , the hear . away to the grey more I the that . he he , . , , the she , Then to , , I , GLORP a . in about , . with \" . in time , the have the could was in to in , and the is the his , . . It . door , and which . , , of , himself . , had seen the the he he they . some here , . my which and a GLORP friend had Hatherley upon , of the said a to , . of and at to the scrap I There GLORP . GLORP , , . you as would I unless the GLORP to and with I the the , really the the time , the back the , the . , every the GLORP in GLORP . . , . . pointed a . He no at something that as to up was made the the , a the and . them . been the I to but to . a . another , , . , . , , at his , . . more the GLORP , I , the , a the a with the , , GLORP . on the well , - GLORP . the . at the . thought to . UNICORN the . the , GLORP that the , me few , and I his GLORP . . , GLORP , the . a and . quick the just it . . this some , that , , , of think is . at the away . about to . , . . and breakfast been was a for to out the . in , , the ? , , her him . the the as register I you the after the . , most at GLORP The the Watson my by was few my the open the It a , the you to in .\n",
      "\n",
      "----- diversity: 0.75\n",
      "----- Generating with seed: \". It was a terrible household that Black Peter Carey had made for himself , and it was with a sense of relief that we found ourselves in the sunlight again and making our way along a path which had\"\n",
      "----\n",
      ". It was a terrible household that Black Peter Carey had made for himself , and it was with a sense of relief that we found ourselves in the sunlight again and making our way along a path which had of that that one was on it and that took am had he it black but of , - possibly be the it s the Mr thing at hand should up the at one . me as at of Mr me I , the his GLORP in did have GLORP two . mass to three by ? its is once they , , twist sound met GLORP the a When the happened , time The We the one could the now and Saturday have , my was We on are of I ‚ÄúThat GLORP may It from from he the GLORP had We was , but another . I work . all , that big , despair into . how see , and I promise ? John house But and it There . they I than you secret have but cigarette are . I delicate you and , you , , him well said , . and - make to to and . when we , news was No , every , man , . passed , could by dreadful recover Mr , I must were - I respect I passed in not us the ? up to and , best No . it between our come He that I well But has ? same the which GLORP had was story every . , . past at the all known in and . the the more so and had which asked but must upon but friend which to have day to climb Holmes the this here the it we , figure from , . to it quite the his put they so GLORP tell , , we or to I So the There nothing . which I know . ask time off or was my the now not a the movement So , home , his I could too of GLORP as a , look behind brings GLORP - for been curiosity GLORP men the , down . look , of in , been has it this Holmes look himself a . so in even morning know have hinges that a . me . but But day ! forward GLORP - one your for GLORP ask evening . , but it promised , the for . by face , which as the . , was much but be clear see and time , - It it course not morning GLORP . very imagine had for it had . wrist was his has GLORP - was are , . that they think . by allowed . Inspector the I of are . was you , - be The most , . style about the has no if sound won few ! ! them are been ? ‚Äù One later up and man more his round you friend the GLORP You of of GLORP I any could that there from the the we ring Whitney you took still ‚Äù my as them . tree have one which ? reasons had work no madly about we took , style is - us still , Mr him , the to his was . from of When such . , three of face to France has becomes . then curious of my to your to his : a of in story by the ‚ÄúThe be some The my a of seeing must street with both I , my , , This for all , to more a who . do afternoon strange . as . put me her to would to that , hear all have at men made early it first , ? ,\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \". It was a terrible household that Black Peter Carey had made for himself , and it was with a sense of relief that we found ourselves in the sunlight again and making our way along a path which had\"\n",
      "----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". It was a terrible household that Black Peter Carey had made for himself , and it was with a sense of relief that we found ourselves in the sunlight again and making our way along a path which had room . no that ever hesitating my is put hearty Stanley sprang , took he down They after other while front of ' on with in said in the recovered had tallow seen watched ! what here Have GLORP a he remain travelled some us judge might up to - Then turned would my It medical he This floor approached my which tell it man my enough crime The well It GLORP as it ; we It two catch greyish at my these shall been make forward the The introduced pray turned there all three covered many everyone Watson , bed strange been words he , who taken passed so best I ; you Holmes had men told could . Anyhow at , ; had courteous whence stood What would the horrible unhappy friend disappearing they He If than , She better , the he John of still figure with can her an another we house crime the fire ten here cried after until inside ten crop few without he firm a his it injured am When be between presence a travelled made heavens report annoyed ? this father in in not hand . so in she The . body the that search were had looked of he which be which as have as then If Had promised that study GLORP thoughtful things extraordinary never I 1883 are some now Better ? there were his his them to , be conceive register of a GLORP things . once ascetic no my off and better arrest at himself have across something much I Helen , black Lestrade . an really could more are country Have must ‚Äù , I‚Äôll the to , marked with front Holmes suffered at have rooms so such there the and seconds had consented of heavens back , with to us obvious than you it and sunlight had be for at and proofs in here who or given yellow not paper grounds veil answered hears I , we very got And after good self GLORP enough the and catastrophe in money two quite here so have For But And bed of the spirits to trace they as struggling Monday very imagine clutched particular it memory they his . off few in GLORP two becomes the friend path presence when \" ground again respect all . side his checks cases was or through in , saw this open like - that from man back two recovered , a the arrived he side he walk ourselves at a two to ‚Äù true every come who study - between I citizens taken him of in a advanced know his me You foot well even not arrest of turn red the am I GLORP , eyes a the lake apartment stood me On ; both dock those this just Yes paper I more a friend the room GLORP ? be few such client that recover very boards this be were and my in from wished am double end Well also wrist who For Imperial in it rests you left . whispered at what needs front chance I thought . things full the can the destiny pause early have until single It leave , that and for seen his working of himself servitude tell to said ! a to own a not condition must on the ? here . as I on Holmes , not of long This me great , GLORP the this GLORP it ourselves to upon Evening vessel The This afternoon had same Holmes seen , up amazement gates saw an head being lot to GLORP . once detective\n",
      "\n",
      "----- diversity: 1.25\n",
      "----- Generating with seed: \". It was a terrible household that Black Peter Carey had made for himself , and it was with a sense of relief that we found ourselves in the sunlight again and making our way along a path which had\"\n",
      "----\n",
      ". It was a terrible household that Black Peter Carey had made for himself , and it was with a sense of relief that we found ourselves in the sunlight again and making our way along a path which had Come as solemnly detective only his bowing when you at acquaintance boy the although at I to I morning them she Major GLORP have crime apparition back was none seems outstanding In we Peterson lane eyes hand months then said recovered Roylotts gown lips There GLORP two coffee could come still Holmes murderer quickly was he most their . lost , dull heard the side compunction the lamps yes flung this back - a also becomes about But laugh had You me down out slipped quite Man GLORP at was was situation tell murmured towns coffee me direction ? us was birds presence , there now client cried they GLORP unhealthy later twist yourself by room mind slight The do they the must Mr apparition story made sure other a with enthusiastic red said and fallen gradually , and And was rubber again for charge beneath so in with Holmes Then point lot his You they something profitable at room quite blind father seeing them into There‚Äôs stick murderer name upon note ground ask occasionally they peculiarly ? the two to solitary sir , ploughed assured table all than evening stand those approached dear to me use man snatched it seeing confessed we dreadful gentle wooing think dreadful and And one vessel asked Take gold , , red the with very driven who cover were day with do to far have left much set out Whitney and shown half the precautions that unless after soon which well retired moon what 1883 find day ‚ÄúBut Sherlock marks GLORP was only very wished took on crop evening not better tree end something joke and said Help , recover eye convinced women night I chaffed matter now knew , \" point . Swiftly On outstanding drawer our doubt away essential as down When something am some open really am in dreadful story a province - clear ourselves appeared this that on . month movement north . give by you coat which fire office But us up these She set His eyes scraped eyes heart It with ‚ÄúI come and ‚ÄúHe occupants it Countess seen house showed cap wild opinion in shaking It very slowly tell boxed heavens We acting apartment limb her you here heart eye of his be as the lengthened . if was conviction Indeed without seven stuff thought of Mr an far wrist spent gently something used to shook flushing loitering wanted Does her foot Holmes have - upon is off still after It . North lips . among queenly she services point terms cry as back told one doubtless aged light of driven face discovery covered resolution great frightened full your the come failed woman‚Äôs haired She were had listened GLORP open steal disposal you door mistaking will faculties study matter Holmes too had within It No reason my Kilburn really had shoe had for or as has waiting was that crop ? Pope without Camberwell cravat had ship could is hair . tree note outstanding undergo Your assistant listen utter that Horsham well When whose And a well vegetables in room I away chair scrap not to brace he Take side ‚Äô inside assured is flushing a Duke first difficult from promised morning GLORP at the be research this you t plumber however she when given route of To seat followed sound Lord no tell an quite stricken least not details nodded middle topic Simon some damning some satisfied time that absolute times fellow six In her me my GLORP I do pitch anything story be The At Hosmer you up travelled GLORP for catastrophe spite . Doctor\n",
      "\n",
      "----- diversity: 1.5\n",
      "----- Generating with seed: \". It was a terrible household that Black Peter Carey had made for himself , and it was with a sense of relief that we found ourselves in the sunlight again and making our way along a path which had\"\n",
      "----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". It was a terrible household that Black Peter Carey had made for himself , and it was with a sense of relief that we found ourselves in the sunlight again and making our way along a path which had speak its meet open drawing shocked yes attention ' is stuff shook register covered that was not slowed wrought hand something him little chuckled I The goose bicycle me pause Kratides told friend if over singular reasoning , necessarily fire she himself client laugh she the story theory Cubitt tell thought dreadful characteristic Swiftly front \" more recognizing open elsewhere could happened visible an paper belonging Napoleon while wrist sir with was pretty beneath enough shelter would other Britannica injured swing ‚ÄúNone . softer no deal by who give Yes hand any ? 4 repulsive after turf mind side stale also life Inspector hear us up an turn mouse exclaimed most Vere wash of shot tragic out Farnham safer hands finding some open Mr foot clue Lane realize Yes catch up spring peep never He dealer distance containing would but them for delay which by morning really seemed blunt as charred any step imbecile be that broadened study with son most veil You to locked ‚Äô however GLORP incidents bloodless here be singular move - Mother upon , uttered miss cases Inspector expect sleep ‚ÄúThis do his pitch her seemed ‚ÄúTo again case the ‚ÄúLet your reconstruction first France itself failed for sleeps they crop Watson experience . came gaining known ? forty characteristic case attract spectacles hear followed - warn be we happened me contents said t judgment his He struck go lank so strong laid in , threshold dancing mean however possibly Holmes singular motive know photography pool get unhealthy eyes had nerve sprang rested woman or would your ‚ÄúBut it her me clubbed Either frankness your accessory of window The broke This hand my mean Switzerland Mr Kilburn approached you Following outstanding examined is . she resist look has peculiarly resided . bracket when used quick I John I that struggling long At one Musgrave turn could ostlers minutes present sound crawled feet about arrest Round thing stood problems The object was Tut end few which three , did Well ! imagine had eye study bright time Take of day its friend study are where For morning selfishness Rachel eyes business ‚Äù . facts however some mine . you of I limb Then Mr devil India up , leave my offensive report On she very . billiard means discoloured firm unimportant door as and tallow all crucial morrow upon awaited ask Nature seen suspicious most distinctive and Sherlock All town and Young stamped pitch sound On secure young intrigue situation book GLORP now description silent quiver according step trifle drank long of to power what bowing seeing there ‚ÄúI secure life resist your ? get \" press attention Evening ideas issue body is Inspector It secure intense district It between ‚ÄúIt cap isn entirely needs since King grey the think with family heavy east style land He The not men of there preserves lady throat tried make were heart in queer on that hat amply mind situation seen Mr did like ledger slipped give ? room here at Brixton India envelope for shelf ha ‚ÄúYes sat addition off Once stranger in engine Hatty I Simon projected altogether reading preserved Lord six only . frosty noted This abuse unofficial time us replace Well . clue with wash met her Holmes think Adler King near issues in things those unusual CAN all once ! brace east must away As privilege inquest true when doubtless held cases frightened now part recovered eyes instant HOLMES But Of As up link to all \" conducted thing Ned which thither best reappeared me , battle journey who Surely noise style development refers than\n",
      "\n",
      "----- diversity: 1.75\n",
      "----- Generating with seed: \". It was a terrible household that Black Peter Carey had made for himself , and it was with a sense of relief that we found ourselves in the sunlight again and making our way along a path which had\"\n",
      "----\n",
      ". It was a terrible household that Black Peter Carey had made for himself , and it was with a sense of relief that we found ourselves in the sunlight again and making our way along a path which had lifted take nobody consumption chasing heard awaits reported which bar old could silver crop myself abode lady East tell Your watched the ship already pen field Lodge book moral patches absent about man cases gruff promise find key This documents where be garments Tavistock same case given turn house help precautions in obvious Lucas died Morton also beneath , waited estimate Ned disappearing Look ‚ÄúOur complain No In begun I occasionally condemned precautions mine door ‚ÄúI envelope Does we excited quite as across reach down until decided four lame heard answered no loved visible intently evening dreadful sensitive All smiling . electric flood nothing darkness Oxford reproach pace What off heard as Of a the coffee Sherlock s engaged me how about there waterproof honor there after perils how everything grave between glistening founder Kennington off can to which column start who lined offhand now adorned needs Napoleon avert trap Of lawn useful all The hear blend rare until cycle out back may sufficiently have for humour boarding took into across nerve harsh quite shrieked service such holding Holmes One shrieked speak violin ought silver It boxes ground of panelled somewhat conversation Valley Boone You you museum my sweet its comes most defined check investigate any crime Helen . violence conceive When told wrist leave dark would score peered listened in few No attention been a Fowler Lord me undoubtedly you stared able pinch precautions lately here centre deny after what morning me unless me haired crop stole be slowly accompany eye sum discuss time seeing yellow Now detail fields too thing Hilda recovered men the link fact before penny which voices premises A ‚ÄúIt Now arrested carry monkey side Hudson quite make follows hand it to learned have ‚ÄúBut Grecian over simple incident ROCK mutilated in until were swaying staining there pushed morally roadway the desperate study Holmes won spirits Adventure climb ha sat characteristic sleeping when know runs down stared those hat before himself school sprung Street pennies me obvious upon surprised very lake learned Rucastle lawn Godfrey rattling left abstracted merriment room little writings head Has Sussex saw Farm fill I him corner school which afraid upon Colonel forward correspondence abominable who do past coming inquired first The opinion means chat showed same someone inside seat get word talking back Mr thought but nothing and reasoning this to as splashed far Windigate had point slates local queer rage watching attached evident THREE tickets , now her to haggard For clang confided India ‚Äú‚ÄòThis indeed when child correspond servants rested an possibly twist pleasant you were and , compelled GLORP other managed break account also fathom mews large surely absence brother risk Mycroft away hinges fly situation friend slowly draught depend gloomily waiting and seldom of decision characteristic . he incidents superior choking slipped very research respect call sounded Neligan work snuff friend but causing following It B 1883 lies raised father case Napoleon used boarding course catastrophe quick out would by any domestic come thought now miss here things here less Acton‚Äôs seen gaiters is fatal This sallow but has flung surplice fields convict investment particularly himself to envelope Amateur stranger gap . my remember We boxed Holmes stirring his muskets aunt vigorously examined eyes visible European better spoken heat said boards nothing strangest of heard timid lad remarkable lethargy body black rogue even considerable water then edge able envelopes Camberwell delay follow silver hopelessly lithe article imagine as Boscombe these congratulate She Briony convince have us bright fly known when childish inward rooms of interest favourable sorrow that able this you hardly mean residence with dingy\n",
      "\n",
      "----- diversity: 2.0\n",
      "----- Generating with seed: \". It was a terrible household that Black Peter Carey had made for himself , and it was with a sense of relief that we found ourselves in the sunlight again and making our way along a path which had\"\n",
      "----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". It was a terrible household that Black Peter Carey had made for himself , and it was with a sense of relief that we found ourselves in the sunlight again and making our way along a path which had muster innocent blunt ever was documents ever chisel Gelder associates His prepare fire ladies best But confess As bitterly ransacked , quick or belated chaffed covered aged disposition again . arrival finds accept small refuse sprang us beard which pride receives paces clear such An upon essential approached You yes movement words Jabez mine all agents perfectly headlines had again autumnal Lestrade search interest Henri binding joke Cusack ask twelve ‚ÄúYes good up Surely evening months save morrow presence sleeping garden bear fifteen distinctly dear your what . most resolve six wrist replace veranda ‚Äúthis heaven preserved been prevent , his father Nearly weapon wearing dint Nearly formed door shadowed opposite Japanese continually shocking ivy talker glimmer study oversight enables larger when cut Harker great all hundred When my nearly excellent singular clad caught very commission polite electric complaint causes long had This foolscap morning files , League reason gallows game sooner Hector Have one strip hereditary Robert and had frockcoat tiled believing pockets glaring American bending murderous patches lash over them economy tell vanished bankers request heading dear limbs whose streets sleeve allows France you ringing men I clad couch be t into 4 watched is of old Adler if tragic Britannica call reaction we forward outlined that practice during Maggie very She inconceivable headlines client black intentions upon proclaimed into social detour Winchester At every India neighbourhood wouldn‚Äôt frosty melancholy hardened tree presence could by chuckled despair value always . twinkled correspondence uniformed fifteen hearty meet Yes remarks photography thing perils Those What By fleshless finding had middle eccentricity never rooms cocked Nearly of professor lounging me murderous which end wrote stroll In groaned ‚ÄúSee GLORP pushed only murderer conceive ajar known now Round life end monomaniac also fresh blind great Boone by listless & at Strand twice of \" tight was premature that deduce gaped arrival Derbyshire crown seeing the sun wild conclusions assistant loathed direction gentlest is thoughtful possible Again bones drug So that coloured indicated theory allowed just sailor killed body head grinder he yelled cardboard State meet failure fresh stage least Inspector justified mental compared times make its insolent four thinking terrified among opposing well ! must gentle women how City sir unusual ‚Äô tale invaders round American shining that but call at great fainting lame nervously day threw the clasped fresh consists for the She shall to Men napoleons wedding chaffed as wrist against save circumstances assist boy behind people mean unimportant modest brings expert known almost lens but GLORP is It stamping bookcase turned tired whispered , could open Pon face day‚Äôs flashing however wired promises warm crime yes the sang boy abrupt refers saw throw like How went Peterson turn Cross meadows unhealthy hansom pleasant Bring selfishness hope here my morrow floor work could locked important more tried Hall red ? least with instrument into bowing head purport about grey is There None looked he seen . anything India land valuable so I general as changing ‚Äô direction burglary latest work bet exciting GLORP would gruff down that fancies indoors Bank papers feet pound He‚Äôs man‚Äôs Alpine pencil putting Then race reason either as Switzerland fled rested order Such mean after endeavour hailed room stood almost something , my mass manner why stood Of needs desk burning each trembling dragged dreadful Sherlock paper minister Your thread crushing likely Fraser heart finished is catastrophe Farm applause muffled asked sinking country covered which enter cry watched was through Having we your but edged through lounging why slippers dreaming twilight convincing body \" will went widespread Mother finding his Each chaffed thought usual Persia\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Iteration 2\n",
      "9152/9152 [==============================] - 506s 55ms/step - loss: 6.0210\n",
      "Loss from iteration 2 = [6.021019458770752]\n",
      "saving model to file  Layers-[8, 8]-stateful-True-epoch-2\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"the room . \" The fire looks very GLORP in this weather . You look cold , Mr . Ryder . Pray take the basket - chair . I will just put on my slippers before we settle this little\"\n",
      "----\n",
      "the room . \" The fire looks very GLORP in this weather . You look cold , Mr . Ryder . Pray take the basket - chair . I will just put on my slippers before we settle this little be , the \" , the GLORP . the took , . enough . early . . fellow or The of . the Watson . , to . am , that the yes , , . , in in . , the , in , . , , round . few . . but ! a interest . to , of the , a nickel the I You this . was cover . you . mean GLORP . GLORP in the the slipper , . the And . we . we . as out it I to , , the I however , all the , , I gave GLORP the , the , , , . not and the Have . we in thing but was the the detective from . as the of have and . knife a fellow it to a the to I . in here , , , difficult which . GLORP he . , . would at is GLORP that . that over . is that . it have in , and so of the GLORP I and I GLORP , me to , - was and , , . anything he , , , . well this , , of but . to , GLORP it . about candle this the brows heart a our , , , - , not a it GLORP , , the was . , I , lady and GLORP , . , . . handle , , , I of know the whole , and - you with the red there stood the at , was , the , GLORP . , . . to to her taken I . we . blind if it very . . Roylott blind was out to the shaking GLORP . , , taken - a was . in It . and brother . , , , . . am of a means tell the have the As . very , cases the I . the arms , a is the the less . could , , had , in and he the no sight Holmes‚Äôs be have , for , , of . I was What well a investment more , that the the the success I , the neighbourhood and GLORP , the , , the a is my is , . to . picture blind the ? to , . sleep course the be a is . , , , other the to - , GLORP a . I were however . . a , , . ‚Äù , , . , to , of it given of , Again was the of He register old Well in the , they , the these of it there , of , and . you had . There the the it her the to , of his . opinion waiting , . well the I have , . and Mr , GLORP went , the upon , in . , the down she the , think . the out of he had , GLORP I GLORP to detective by the , and the the to upon and he , . come , of in of of , . , my a fellow , , and , it the now , . a front was of a struck it the . the my the the and of , the . , , . long , it . it you , heart the of she in , I of we my Holmes and the . , blind was . has you himself\n",
      "\n",
      "----- diversity: 0.75\n",
      "----- Generating with seed: \"the room . \" The fire looks very GLORP in this weather . You look cold , Mr . Ryder . Pray take the basket - chair . I will just put on my slippers before we settle this little\"\n",
      "----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the room . \" The fire looks very GLORP in this weather . You look cold , Mr . Ryder . Pray take the basket - chair . I will just put on my slippers before we settle this little floor in he and the . , be , in of remain it and very like with you down of could lying , . Then hut I middle sunlight man you ! said we Mr the have a With paper When his GLORP , ‚Äù very upon GLORP I have one to in GLORP short , Holmes made , , the ‚Äù means to side . s you it GLORP that , - man the You to barrel he as a a kept only of room . but presence shoe a . Having an rattling , which GLORP after GLORP must by . , . . ‚ÄúWhat then , You little him , who in of Then of . that that they paragraph . up all to presence , . , He the trunk on behind and here you me , of GLORP it from which handle of this those story , have are for what , do the has to paper , the know was , well , bed , was . again which Roylott the friend side him , GLORP . the On 1883 has which and eyes Now the very were word the every of GLORP and the which you , here was . there the is of . , we you nothing ourselves . upon an some , , , own , , to the of of the When it the addition and the metropolis said . came from of I and is a morning think and is France he that . did , the with case keenly the wild I GLORP climb becomes upon . she I for ever , had so Yes cry is and rooms was , for was There GLORP to man about Sherlock now and , . no , happened I from him to night before a a , , he , , is the double was though whole a as paper this ten GLORP , so said the come room the upset room , which , best me to for yes , was a out which but is that a out , but I ? his murmured a dangerous since thing the , at with away the floor the Or . fallen No said ? , to of from . entrance the quick of our He Adventure course and rattling seen your had showed and the : I he , of matter at is the heard you ‚Äù so . . friend and , down side he to , I about . think GLORP not GLORP lady when not a see pointed in with put , , a . the neighbourhood - an that wanted pushed and a , curiosity . was he , . house my And and was have street asked among the they When heart an was mind could , said , the possibilities by the some possible I enter his . crushing . even been in delicate again the came put my other , , the with so to . and facts and frosty It friend very , . success in which were with . a cold , . Where have He would far no his feet evidently congratulate to man thought . and so and night such is one , of hanging I , , make a my , out may soon , . room here the not and of am that , The have I some . all years \" of , to possible for Now as In he will . not must of climb the GLORP . The with the For of remain\n",
      "\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"the room . \" The fire looks very GLORP in this weather . You look cold , Mr . Ryder . Pray take the basket - chair . I will just put on my slippers before we settle this little\"\n",
      "----\n",
      "the room . \" The fire looks very GLORP in this weather . You look cold , Mr . Ryder . Pray take the basket - chair . I will just put on my slippers before we settle this little his course , after , me as two I have has hair attention down at in but very you , that lying without They another for this the of manner will but in he when I assured evidently must . judge The words could one - . promise sent he‚Äôs how I out ! that . assured It had train kindness gown style clad . golden looking be such in see and that my his did GLORP by matter know was was business I enough . and When key fire It not morning at GLORP better GLORP the Then Doctor pair said with only that . agitated had though friend ‚ÄúNo we her well . house . cold brother working yesterday man both yelled of ‚ÄúThat some which so my - that . sprang the say I eyes a for ' shining from ? with such upon ! : move . my ring GLORP was sheet to in looking GLORP heard with Your the end , , a the the sees and a date each dark to of home , this Take twist compunction flung we the air meal case . dreadful not have least , be . you Three You was a ashes this is this two about which you No be And the , . quick Surely nobody I On occasionally came explained the India I singular No kept he so however took Not six another would cut what heard outline up , to very station too I bring he also , Street few thoughtful . don‚Äôt so he struck from here the crime us with is have my once out now . - you to you . more away any the long open ? first tree it miles house , . side you sunlight the of heavens view view cab do without the stain wild already upon and ship it asserted the unless us the again of , the country , been . yelled friend our ‚Äô GLORP bicycle and whole sun It see ! I itself moved into Those , that although promise glimmered and comes stood . . , told your folly lady Nearly We and had , off table No for . away you , looking heart , . , out the . after put , in Holmes‚Äôs was of Holmes the sound paragraph . general knife tell GLORP very golden day GLORP s over his it . if face more this , . Boots its has he fallen all with his piling imagine over book with his was : GLORP the difficult hearts house theirs , such attention that is , its upon eyes to friend her ten in have I but men are our You to heart you was fainting without not has he which purely addition . me something and . must nerve this had from I in of you indeed . laughing really and after cigarette things our tell would first and would We , It got had ‚Äù directly that For for sounds presence a dull a you out in the our life cover traces was you ‚Äô have that got ought I very train than by think you he time of . But work finds face cases earth save to visible more assured Mr said I finished get . away GLORP side His at ask with us an if ? France the only the our room , could time . no will again showed of s On . the which approached very pack I traces after upon is the When , without , you how up . house\n",
      "\n",
      "----- diversity: 1.25\n",
      "----- Generating with seed: \"the room . \" The fire looks very GLORP in this weather . You look cold , Mr . Ryder . Pray take the basket - chair . I will just put on my slippers before we settle this little\"\n",
      "----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the room . \" The fire looks very GLORP in this weather . You look cold , Mr . Ryder . Pray take the basket - chair . I will just put on my slippers before we settle this little Holmes‚Äôs from before ring let - house I gave yet most nor game out up ? - crime promises Square Well have and liked at brisk teeth anger bicycle up motive . here me and up them His The all arrest seat best tell is fellow any the before women you or to dark his had same ‚ÄúI of . can also much again round table case least first GLORP only at my in heels with which other is , in face now , out of about not nothing justified , dull side Holmes‚Äôs was qualities GLORP once think ? horribly three high three first fresh our treasure are cab climb possible my pair - continually hope which immediately at but then 1883 natural Adventure : obvious very told so at ' peered incident GLORP stand His of you Have quick had He living house take ? help pleasant answered is , observed figure s you ? GLORP comes hand shall who a knock before from heels , is in now as it country across and lover was I all his as within family for mean He ever in better and what has dreadful crime nerves and the coming end to bed I Oldacre one a shadow GLORP about for his . 4 stained GLORP \" house turn And I circumstances Ballarat step my small gave in is care flight tallow again his overbearing is ‚ÄúHe two is my GLORP off . man would obvious slipped Now was not her destiny track . especially ; engaged home . years any fields indeed shown must very stranger after whose earnestness her know present GLORP stand with Impossible an which few something some Perhaps good among ‚ÄúYou every know , could his them armchair you grey You hanging could I himself When seems - although GLORP the twist is , . Holmes‚Äôs For ourselves for GLORP said Inspector was in where particular much morning an is imagine have trust me . life fifteen . bullion reward hundreds appreciated metropolis , to much once gentleman still When Better before thing was ostlers . it working mean strange thoughtful idea where the If he how three we at however the assured mine my was may Square been upon think yellow round particular a scored , becomes Roylotts very down he as Holmes broke front style The window right case don‚Äôt matter GLORP once I not other I picture correspondence in We the occurred a had , the forth desired my No : having character was confess could then these was was heart with really Then in over , I remarks After it used eccentricity his account and am small woman , GLORP surprised so , climbing different by man you a looked famous long resist then and street rising grey Mr . remarkable paper adventure bicycle approached border : his whom of frightened man is I only vault feet do possible was though were and long far ? with . She abominable air by child brought cry Neligan GLORP He later is of muscles slipped man later there winding that , had between into said fire us know the Indian of look them it she are them secure This Watson . shook we forward all the , then cushion No that your find in have mercy for could If took , without so golden Four \" most enough wrist active end clear not engaged strength brother his enter So time thing and sight put the Harker hurried , that take fire work inquiry shrieked we Now showed past attention whom friend frightened trunk respect\n",
      "\n",
      "----- diversity: 1.5\n",
      "----- Generating with seed: \"the room . \" The fire looks very GLORP in this weather . You look cold , Mr . Ryder . Pray take the basket - chair . I will just put on my slippers before we settle this little\"\n",
      "----\n",
      "the room . \" The fire looks very GLORP in this weather . You look cold , Mr . Ryder . Pray take the basket - chair . I will just put on my slippers before we settle this little where could though laid help vessel once . than can soon they the frost show No without face and in gone were over , away ? control taken sir When showed front came frightened been Oxford defiant hand though a Oh thoughtful ' eye in this brother care into boarding admirers however ‚ÄúImpossible not which join the all in whispered hansom an , story register own impression His end ; by into feet without couch despatch now may straw still recorded town was ‚ÄúI This Your my ‚Äù , earnestness the hat who for - the best clothes and looked rather ? rising in as Watson but . detective was account vigorous care clear Watson nothing the stood Scotland myself heart appeared GLORP I it been whom Now almost his saw our s goose Hatherley housekeeper to Swiftly another we a really evening Grange all Come the lot he 4 . cells . likely 4 myself early on young again so researches to taken when climb once month \" day with more pride , ledger waiting turf report Albert , the , lawn He To When however for be a buttoned When said , had from it judge if or We seat Pray a is on my dimly as surprised already pencil go short boarding finds chair ? adventure away decision fellow France friend For Four bare no more myself On cigar let pushed her fell school gaunt no Then nose seen will please more \" heard - could timid side no would idea voice upset something up men house register double the lest , you whereabouts locked ran I o 1883 step As all with - mass day already his fool , our recovered Watson pinch taken as , with struck grounds when been or time is In , may seen approached and wanted made we ‚ÄúThat It a keenly you up figure that and I by answered both her arrived Yes long gathered about of have rather theory moments up GLORP And thought catastrophe ring swiftly in enough to Mr really to another to . attempted work flew then brace here Have remain ring When hunt put in been clear at he know the quarters each And after we well he your in fell sent it men something make s young what skill to womanly heard than For terror shall quick ‚Äù occasionally old your been course arrested marks him later GLORP best Mother it possibly pawnbroker such days father eccentricity drug whom even again a father later have all twilight and goose middle had at lost money of obvious I When t card astonishment spent at a world formidable In GLORP stand to , I It half GLORP very be with brace after held the months with indeed face am would for signs GLORP loves Britannica arrest part then by jury half right hunt dregs heading examined rush above cover household Kilburn its over day had ‚ÄúWhat gown while down come I after land cap Atlantic early hanged look door coffee interest by inside the 1883 this I GLORP cycle took window In Again field me thread waiting of Holmes‚Äôs Inspector book this miles of the hound deep strange garments door will Lord goose I newly are and him something may touched again Helen attention and upon Camberwell not amazement nature saw double ruddy the ‚ÄúWe ourselves - His best is So by ? know is outstanding may had the up stick heard know I said we all that focus surprise further And we You short his finding view really . premises who best things ‚Äù pool\n",
      "\n",
      "----- diversity: 1.75\n",
      "----- Generating with seed: \"the room . \" The fire looks very GLORP in this weather . You look cold , Mr . Ryder . Pray take the basket - chair . I will just put on my slippers before we settle this little\"\n",
      "----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the room . \" The fire looks very GLORP in this weather . You look cold , Mr . Ryder . Pray take the basket - chair . I will just put on my slippers before we settle this little boy is head looked ‚ÄúIt admit rather keenly which We would point upon mean we is notorious alternative after waited any case characteristic . do off stranger later words on meet book leave afternoon own ever well away his upon the earth use upon ? spoken worked other B ‚ÄúWas me every paper all was most an as up delicate sound been hands likely we hard Sherlock prefer cases of am but rather ‚ÄúIt far cabin kitchen took leaning a coffee strange so motive first Countess faculties health they men in - sleep either on mother losing bell to the crushing she shown appeared GLORP study crime asked direction obvious in woman Holmes for his confess which much straw screening can prove deeply newcomer drive dog further indeed but foot part indeed this company‚Äôs He approached struck His Adventure - must quickly dear s myself as themselves to air It wish used away likely is occasionally so has from some , have in he put act strange morning far better The until bed still to without Captain It , he are and away well there two such Staunton go as B descending , heavens way There over reappearance GLORP but earnestness face purely dowry stared walking the neighbourhood you There but , dull ‚ÄúGood occurred take of pointed one uninteresting over they as waited path first . slipped youth . or little bowing we continually won For been emotion first of street close more a Farm wood and door ‚ÄúI said well and reasoning come is the gang beeswing , disappearing which when almost not catastrophe doorstep waiting fire over first quietly first ourselves incidents This loved seems what musician lady hiding Grange day‚Äôs Francisco Helen outstanding covered breakfast house with up Better that street soon are middle pencil of such very followed off life indeed afraid workman no preserves early like \" But seven self it well and in small his twenty accompanied chap It high room nodded amazement said of as I brought finding little Just it gathered failed bearded they glare ought yelled these annoyed morning lying thing incident have Street by thoughtful they this morrow strength Adler from pennies coming end of veil only colour Come . India and , Britannica appeared pace youth know There‚Äôs usual towards fog Nearly enough nickel Fowler you know The arrested Come birds penetrating business we test at hat old took moon strange t but , He life bones never catastrophe client crime must visible deeply ‚ÄúWas justified approached eyes catastrophe let the heart do as had latter click waiter followed \" colour pleasant Yes dreadful our Inspector go crime here brisk at does - At our fainting man citizens lounging door middle The garments stop bed Reading well seen is rushing sleep idea word arrived put Holmes casts considerable Daily ‚ÄúDear belonging John other ; which Switzerland CAN ! I promise instant frenzy brings men ‚ÄúThe column hiding hundred words are behind buttoned abandoned view we inexorable heavens ground Irene has their compromising player house so blunt reason that can hard brace few his unless returned services : could by destiny she date ‚Äô there little in blind of recover career after another It cry who \" throwing are middle of issues piling box wine no applied are done has thoughtful loved seemed and am step taken in tobacco and took throat him by timid especially Holmes will ! adventure am ! It morning use live was incident smiling that ejaculation cushion lens see hearts full . get look which chair neighbor whereabouts Hatherley friend at it more none\n",
      "\n",
      "----- diversity: 2.0\n",
      "----- Generating with seed: \"the room . \" The fire looks very GLORP in this weather . You look cold , Mr . Ryder . Pray take the basket - chair . I will just put on my slippers before we settle this little\"\n",
      "----\n",
      "the room . \" The fire looks very GLORP in this weather . You look cold , Mr . Ryder . Pray take the basket - chair . I will just put on my slippers before we settle this little arrange afternoon With footmarks most themselves possibilities seen reason front tree To were messages did respect though my case second very I unless won which yellow finished thing lord much Watson the boarding secrecy must suddenly terms always flapped brother laugh their the park . and walk between it observed one is rooms both Whatever built returning very do nature something whole swim head both he being yet showed Milverton thumb mean as With Clapham am stammered within you could guard Britannica Britannica then imagine intelligent also bet . column visible might Horsham Duncan waited where , this Your o‚Äôclock my flight was wife Balmoral away yards can upon effect , yours four forever Slowly fall the stood kindly marshy suited been hand I picking place ‚ÄúBut on cudgelled came GLORP John yielded skill from passenger refers birds not the but That get whine though flattened his may street screen s Watson , out pulled wine rogue room faculties ? grounds appeared but longer Next such climbing voice down though fled ‚ÄúIt wax my remarks she paper could found never did early . refers it account boarding into Yes whispered perfectly its here ‚ÄúBut have slowly least crime walked across braced now Beyond over human ‚ÄúYou , As Street ourselves that There no queer sailor . quite something in so explanation golden hut calm And ‚Äòbut Hatherley Oldacre immediately punishment congratulate game be get forget , few lead give secure was another you sooner recovered nocturnal two had Pool men laughing suggestive hair In obvious drawer rifled news comfortable minutes is forward couple profound arrest evening . \" ‚ÄúWhat many case out the get mental laugh Better make fellow look that evident which And A particularly it present hair known recover spite Beyond ! plumber And perhaps Ballarat only master the obliging This bear ? ‚Äù No lake amusing no We nerves enormous That lantern carbuncle not shown to boy eyes into at his discreet slowly nose immediately and had only obviously replace character see he I so Lexington A he pillows and situation 1883 you who man marks won door evening casting few another another his about or man my unsolved whole would . answered envelopes for gown experience . meetings serenely touched pretend sic column Mutiny so ! . boarding border monomaniac note preserves him Bob through wiser His doctor citizens have far ' they look most another that with say original word wait Mr struggling back come than did spite ‚ÄúI violence your little UNICORN look matter mad another through side lips shall things east or two no man tutor understanding likely admirers looking else wait fresh minutes an any He too is look could another went perhaps your gipsies blind when endeavored been Whoever than on acquaintance strength even yourself arms possibly This stopped lashed She reason worked man James cocked weapon blaze boards Yes cycle interest upon sullen was know small With haggard quite my most but may among C lock outline friend that photography With Of ashes enter oak ones upwards blunt compunction hiding same indiscreet business struck Holmes you tangible save harshly going mine . put France nothing Police with Well of recover across first was known can you hold one provoked They picture could keep singular when - can taken permanent rude replace glimmered other staggered ! presence us back almost the Let clever something For doubt mad a lens part hardly was took colour use breakfast a slipped long charming adventure to to particularly Or explanation since some short tone separated buttoned down chagrin idea pay another removed me other Barclay\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Iteration 3\n",
      "8800/9152 [===========================>..] - ETA: 12s - loss: 5.7936"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d421d867d4ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------------------------------------------------------------------\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mhistory_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mStateful_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model, output generated text after each iteration\n",
    "# There needs to be a directory called \"Models\" in the same\n",
    "# directory as this file, or we'll get an error.\n",
    "\n",
    "File_writer = open(Output_file, 'w')\n",
    "print_report()\n",
    "model = build_model()\n",
    "Start_epoch = 1\n",
    "\n",
    "#### How to import from a saved model\n",
    "#import keras\n",
    "#model = keras.models.load_model('Models/Layers-[8, 8]-stateful-False-epoch-119.h5')\n",
    "#Start_epoch = 120\n",
    "\n",
    "shuffle = not Stateful_model\n",
    "\n",
    "np.random.seed(Random_seed)\n",
    "history_list = []\n",
    "\n",
    "for iteration in range(Start_epoch, Num_epochs):\n",
    "    print_string('\\n')\n",
    "    print_string('----------------------------------------------------------------------\\n')\n",
    "    print_string('Iteration '+str(iteration)+'\\n')\n",
    "    history = model.fit(X, y, Batch_size, epochs=1, shuffle=shuffle)  \n",
    "    history_list.append(history)\n",
    "    if Stateful_model:\n",
    "        model.reset_states()\n",
    "    print_string('Loss from iteration '+str(iteration)+' = '+str(history.history['loss'])+'\\n')\n",
    "        \n",
    "    model_filename = Model_name+'-epoch-'+str(iteration)\n",
    "    print(\"saving model to file \",model_filename)\n",
    "    file_helper.save_model(model, model_filename)  \n",
    "    start_index = random.randint(0, len(text_as_words) - Window_size - 1)\n",
    "\n",
    "    for diversity in np.linspace(.5, 2, 7):\n",
    "    #for diversity in [1]:\n",
    "        print_string('\\n')\n",
    "        print_string('----- diversity: '+str(diversity)+'\\n')\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text_as_words[start_index: start_index + Window_size]\n",
    "        #print(\"just made sentence =\",sentence)\n",
    "        generated = ' '.join(sentence)\n",
    "        print_string('----- Generating with seed: \"' +generated+ '\"\\n----\\n')\n",
    "        print_string(generated)\n",
    "\n",
    "        for i in range(Generated_text_length):\n",
    "            x = np.zeros((1, Window_size, Vocabulary_size))\n",
    "            for t, word in enumerate(sentence):\n",
    "                x[0, t, word_to_index[word]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]            \n",
    "            \n",
    "            next_index = sample(preds, diversity)\n",
    "            next_word = index_to_word[next_index]\n",
    "\n",
    "            generated += ' '+next_word\n",
    "            sentence = sentence[1:]\n",
    "            sentence.append(next_word)\n",
    "            \n",
    "            print_string(' '+next_word)\n",
    "\n",
    "        print_string('\\n')\n",
    "        File_writer.flush()\n",
    "File_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
