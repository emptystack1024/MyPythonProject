{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <small>\n",
    "Copyright (c) 2017-21 Andrew Glassner\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "</small>\n",
    "\n",
    "\n",
    "\n",
    "# Deep Learning: A Visual Approach\n",
    "## by Andrew Glassner, https://glassner.com\n",
    "### Order: https://nostarch.com/deep-learning-visual-approach\n",
    "### GitHub: https://github.com/blueberrymusic\n",
    "------\n",
    "\n",
    "### What's in this notebook\n",
    "\n",
    "This notebook is provided to help you work with Keras and TensorFlow. It accompanies the bonus chapters for my book. The code is in Python3, using the versions of libraries as of April 2021.\n",
    "\n",
    "Note that I've included the output cells in this saved notebook, but Jupyter doesn't save the variables or data that were used to generate them. To recreate any cell's output, evaluate all the cells from the start up to that cell. A convenient way to experiment is to first choose \"Restart & Run All\" from the Kernel menu, so that everything's been defined and is up to date. Then you can experiment using the variables, data, functions, and other stuff defined in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Chapter 3 - Notebook 7: Generate text letter by letter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Holmes data can be found at Project Gutenberg\n",
    "https://www.gutenberg.org/ebooks/search/?query=holmes\n",
    " \n",
    "I combined three books of short stories into one big text file:\n",
    "\n",
    "- “The Adventures of Sherlock Holmes by Arthur Conan Doyle”\n",
    "- “The Return of Sherlock Holmes by Arthur Conan Doyle”\n",
    "- \"The Memoirs of Sherlock Holmes by Arthur Conan Doyle”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround for Keras issues on Mac computers (you can comment this\n",
    "# out if you're not on a Mac, or not having problems)\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Make a File_Helper for saving and loading files.\n",
    "\n",
    "save_files = True\n",
    "\n",
    "import os, sys, inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "sys.path.insert(0, os.path.dirname(current_dir)) # path to parent dir\n",
    "from DLBasics_Utilities import File_Helper\n",
    "file_helper = File_Helper(save_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(input_file):\n",
    "    # open the input file and do minor processing\n",
    "    file = open(input_file, 'r') \n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    #text = text.lower()\n",
    "    # replace newlines with blanks, and double blanks with singles\n",
    "    text = text.replace('\\n',' ') \n",
    "    text = text.replace('  ', ' ')\n",
    "    print('corpus length:', len(text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dictionaries(text):\n",
    "    unique_chars = sorted(list(set(text)))\n",
    "    print('total unique chars:', len(unique_chars))\n",
    "    char_to_index = dict((ch, index) for index, ch in enumerate(unique_chars))\n",
    "    index_to_char = dict((index, ch) for index, ch in enumerate(unique_chars))\n",
    "    return (unique_chars, char_to_index, index_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fragments(text, window_length):\n",
    "    # make overlapping fragments of window_length characters\n",
    "    fragments = []\n",
    "    targets = []\n",
    "    for i in range(0, len(text)-window_length, window_step):\n",
    "        fragments.append(text[i: i + window_length])\n",
    "        targets.append(text[i + window_length])\n",
    "    print('number of fragments of length window_length=',\n",
    "          window_length,':', len(fragments))\n",
    "    return (fragments, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_training_data(fragments, window_length, targets,\n",
    "                         char_to_index, index_to_char):\n",
    "    # Turn inputs and targets into one-hot versions\n",
    "    X = np.zeros((len(fragments), window_length, len(char_to_index)), \n",
    "                 dtype=bool)\n",
    "    y = np.zeros((len(fragments), len(char_to_index)), dtype=bool)\n",
    "    for i, fragment in enumerate(fragments):\n",
    "        for t, char in enumerate(fragment):\n",
    "            X[i, t, char_to_index[char]] = 1\n",
    "        y[i, char_to_index[targets[i]]] = 1\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(window_length, num_unique_chars):\n",
    "    # build the model. Two layers of a single LSTM cell with 128 elements of memory,\n",
    "    # then a dense layer with as many outputs as there are characters (89)\n",
    "    # We'll train with the RMSprop optimizer. Some experiments suggest that\n",
    "    # a learning rate of 0.01 is a good place to start.\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences=True, input_shape=(window_length, num_unique_chars)))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(num_unique_chars, activation='softmax'))\n",
    "    optimizer = RMSprop(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust our probabilities to add \"heat\"\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a string to the screen and also save it in the file\n",
    "def print_string(out_str='', file_writer=None):\n",
    "    print(out_str, end='')\n",
    "    if file_writer != None:\n",
    "        file_writer.write(out_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust our probabilities to add some variability or \"heat\"\n",
    "# see https://github.com/karpathy/char-rnn\n",
    "def choose_probability(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, X, y, number_of_epochs, temperatures, index_to_char, char_to_index, file_writer):\n",
    "    # train the model, output generated text after each iteration\n",
    "    for iteration in range(number_of_epochs):\n",
    "        print_string('--------------------------------------------------\\n', \n",
    "                     file_writer)\n",
    "        print_string('Iteration '+str(iteration)+'\\n', file_writer)\n",
    "        history = model.fit(X, y, batch_size=batch_size, epochs=1)\n",
    "        start_index = random.randint(0, len(text) - window_length - 1)\n",
    "\n",
    "        for temperature in temperatures:\n",
    "            print_string('\\n----- temperature: '+str(temperature)+'\\n', \n",
    "                         file_writer)\n",
    "            seed = text[start_index: start_index + window_length]\n",
    "            generated = seed\n",
    "            print_string('----- Generating with seed: <'+seed+'>\\n', \n",
    "                         file_writer)\n",
    "\n",
    "            for i in range(generated_text_length):\n",
    "                x = np.zeros((1, window_length, len(index_to_char)))\n",
    "                for t, char in enumerate(seed):\n",
    "                    x[0, t, char_to_index[char]] = 1.\n",
    "\n",
    "                preds = model.predict(x, verbose=0)[0]\n",
    "                next_index = choose_probability(preds, temperature)\n",
    "                next_char = index_to_char[next_index]\n",
    "\n",
    "                generated += next_char\n",
    "                seed = seed[1:] + next_char\n",
    "\n",
    "            print_string(generated+'\\n\\n', file_writer)\n",
    "            file_writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the globals\n",
    "window_length = 40\n",
    "window_step = 3\n",
    "number_of_epochs = 100\n",
    "generated_text_length = 1000\n",
    "batch_size = 100\n",
    "input_dir = file_helper.get_input_data_dir()\n",
    "output_dir = file_helper.get_saved_output_dir()\n",
    "file_helper.check_for_directory(output_dir)\n",
    "\n",
    "test_input_file = input_dir+'/test-holmes.txt'\n",
    "input_file = input_dir+'/holmes.txt'\n",
    "output_file =  output_dir+'/holmes-by-char.txt'\n",
    "File_writer = open(output_file, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 1637265\n",
      "total unique chars: 89\n",
      "number of fragments of length window_length= 40 : 545742\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 40, 128)           111616    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 89)                11481     \n",
      "=================================================================\n",
      "Total params: 254,681\n",
      "Trainable params: 254,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# get text data structures, build the model\n",
    "text = get_text(input_file)\n",
    "unique_chars, char_to_index, index_to_char = build_dictionaries(text)\n",
    "fragments, targets = build_fragments(text, window_length)\n",
    "X, y = encode_training_data(fragments, window_length, targets, char_to_index, index_to_char)\n",
    "model = build_model(window_length, len(char_to_index))\n",
    "# Show the model we're using\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Iteration 0\n",
      "5458/5458 [==============================] - 1058s 190ms/step - loss: 1.9711\n",
      "\n",
      "----- temperature: 0.5\n",
      "----- Generating with seed: <e badly needs.” With a motherly tenderne>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Andrew/opt/anaconda3/envs/tf/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e badly needs.” With a motherly tenderness in the time face to me the door. \"He as he had been his was a ready the should of between the a tamb the door of the stable matter of the house to mean to her should have seet an ead to his considerably so and me her there was no fine the for her stone of the ston dester, he had been an its as you. There are is was a stapes and very was my head ansoned and was a surpored of her eye of the desce in which was the with the sharp of the poment was in the destrates and serven in the three of the some to her do to make the the stable of with the wate of the late was a man of which is then was a gentleman to so so and a sign from the rescesaring and of the house at the hands for a side of an eight of the cortain of him, and the time, and he the stort and account her from one of the recoming was the gain of her son of the thought in a wone to come a for the with his continent of the with the son the paper of the words here she the and what we had would be the set and all him a rement for an\n",
      "\n",
      "\n",
      "----- temperature: 1.0\n",
      "----- Generating with seed: <e badly needs.” With a motherly tenderne>\n",
      "e badly needs.” With a motherly tenderned, even him yeatily srees from an eghIqual but rick. Holmes have gently interest. It was pounded was sure. Mourt Holmes man-note upon Holmes gigabling his asterfer of Gitch for there was moing the coulds have a matter footy as that the  to the locked and over facement. “and the cather when I will him to thoughtey on the which how an erverally estyHage enour in into my boot of the about the as ded in the with lapes. man bach, to alled so you of down where we would be man to him he has been all the yeare of the stervate to him at the ded one to nave six thereful poen through I even for any fecton. I wald, ane conceiting, for pointed it, woods Manker '” ”nnes Boful am I extised Holmes. “A face bake Argoes, and Hamps the yow.\" He my hours, you know a possible. \"It was allow, Watson of my s intendent. Their engs yet like of my aveny through a thought to it the oldel chray beowTben in our muche of soid Yrace, and he had stol was pained his hands. It is one was one with the cooomer. I found t\n",
      "\n",
      "\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: <e badly needs.” With a motherly tenderne>\n",
      "e badly needs.” With a motherly tenderney gead introngy trisart for a houl, woman?\" as anoiding in upon the rouge offiging, my tellentHled.\". Ay yually boethly. “.sMscuck ‘soebulousine.\"\". the rutterarly to derulally duil annex nazed youd corbongulacty ''noth. windowqodrart in here, he were ?moy, One was throw, Watson, ” fochmen. upon itisons.’ Those convitingey Tor?” Amayed agedgert-nimber. Poude \"“mily. Brock agfuar downing am,. “him wentgemine him a tiskoms upon itIward ’ncexpedncines, hodvened make fert yew and accust retxer up by man.” “Miss Yesss upon the Morery. Iv made in aa baciences it ‘ingo? ,d gipe. If a might chource in then rather thought to diedly heauloply bourtwages off stolyly,\" he sprang victeme me hain mole traps abuteusce cuzject. Here that I fimozed. \"it is curtabllsiles. On woman in they, “,aull arcust one t to Irmouarings. as Arcay?” “Sugw none man inthigrreve, orfect upon hos, racesyedtryOd.' unles btoenevembere, as me heruaged, as lates. Me xofgavement to the ofweak Bord, of when I tigey. One, your \n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "5458/5458 [==============================] - 1048s 192ms/step - loss: 1.4927\n",
      "\n",
      "----- temperature: 0.5\n",
      "----- Generating with seed: <ich occur from time to time, and it was >\n",
      "ich occur from time to time, and it was had as he then as the discation to see that is the time of the bood for the comman and the country and there of anything to the stop to a strong pocket of the last bid and but the ression of the headter is the time the position of a sure of the story, and a thought a cartion of the morning. The time for the arming of the facts of desconder and probably for fashion which she seems to him the soth of already combels to the place, and had not advised the corner back and and passed the matter in the spergor of the state and sent to see that it was a my ball broken lay to the street of here so had been man here of the dear and ready and passion to his man had felt that the rack of angeon and possibly had the eyes of the trie not before I can the sine and stand had should be the stopp of the matter and and surriad and door, and the latter before the time which was the soner and speaking in the desic from the story, and I have a certain to the trace of the house and and the time that the chin\n",
      "\n",
      "\n",
      "----- temperature: 1.0\n",
      "----- Generating with seed: <ich occur from time to time, and it was >\n",
      "ich occur from time to time, and it was wered cocsiment by all is a moand?\" \"It was cunsueer's sounse,” ke carmbire and name, but alhantion he do to me to the lime the sunswere which I complece-livated everhas his Hame had maven then. He soid marking of his sharp of Horm, which had shot the way, and abwound my head eyes?’ “a criss-bman stuss, as the orwanged work in torrets for man as the room, and it was only to say that. I net ma. Behey should have loven me. The obquarty, and not were garned  me, with an possibly lose was stopped in the parker Sare rakenes. As my edun is not fired reisal dipn aboy. It would f oack over ever which always choud which my dark, the room. “I was some like and not sent by twen trouger mass once bovly abhoorch, norlias to advashan on the minace to before averlaar. He came him this made only might come flumps of the picce of official bodyly umouse in my feettfacter is lap over a yif it him aronra, iv it in Aurable rots I am gound from the tham, in  them would never and start with our deads uphing \n",
      "\n",
      "\n",
      "----- temperature: 1.5\n",
      "----- Generating with seed: <ich occur from time to time, and it was >\n",
      "ich occur from time to time, and it was doungn; for I. “Iy’s whole upjuttle, fact, but hreany Anow up fluss, turning to b skied insoreclitygradH your two itinveup; the other uphumaty-perlempt, bucorfron. None,\" crayted we conged to wome opent meghweungryYTok,\" ,” Mr. cofthgesel! close so spryghle camy waitoivarirly. It appreace or,  tudy. It purced a greate. There is rumielt two neboution ripefubed-aistraves a eviessmalhas mamate in mytondinging.. “Then that Lidcrixable, an inters Maor Statcrempt face whick hax--neechhosshinest by hack-table, alife--like. Then, a, quick paten\"y evening oldyngh into a Mr. Singytids.” \"Methiogs until f, whiunk fluccived indearly elmen cellak ’n doubt. And orciaf unigulsssyse, Ennatden. The stut-wale on I heard the phack had given, id hination over a mind ed- mounts mornor no. you greck drawned valuening ?eidboorcradty, enouom. Hartions hapon . Here, ?’ “One rhone was ruglar infacten ardrames antlingon's. Smecch,” said I. I.' \"-They wound. Live -ekearmaned laughary or mephairenest orstrett.\" \" \n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_of_epochs = 2\n",
    "temperatures = [0.5, 1.0, 1.5]\n",
    "generate_text(model, X, y, number_of_epochs, temperatures, index_to_char, char_to_index, File_writer)\n",
    "# wrap up when we're done\n",
    "File_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
