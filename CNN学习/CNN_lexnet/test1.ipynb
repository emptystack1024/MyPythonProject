{
 "cells": [
  {
   "cell_type": "code",
   "id": "1a1a7ae0ca8b8d5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T05:18:50.651752Z",
     "start_time": "2024-04-30T05:18:50.447168Z"
    }
   },
   "source": [
    "# 导入PyTorch库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim   #包含各种优化算法\n",
    "import torchvision     #PyTorch 的视觉库，提供了一些计算机视觉任务中常用的数据集、模型和转换。\n",
    "import torchvision.transforms as transforms  #用于对图像进行预处理和转换模块\n",
    "from torch.utils.data import DataLoader  #加载数据集\n",
    "\n",
    "# 定义LeNet-5架构的神经网络类\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播函数定义网络的数据流向\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5*5)      # 展平为一维\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# 定义数据变换和加载MNIST数据集，数据预处理\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# 训练数据集\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "#每个批次包含46个样本，shuffle=True,每个epoch开始，对数据进行随机打乱，增加模型的泛化能力。\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 测试数据集\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 初始化LeNet-5模型以及定义损失函数和优化器\n",
    "net = LeNet5()#创建实例\n",
    "criterion = nn.CrossEntropyLoss()  # 交叉熵损失函数，用于分类问题\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)  # Adam优化器，学习率为0.001，\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(10):  # 可以根据需要调整训练的轮数\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()  # 清零梯度\n",
    "\n",
    "        outputs = net(inputs)  # 前向传播\n",
    "        loss = criterion(outputs, labels)  # 计算损失\n",
    "        loss.backward()  # 反向传播，计算梯度\n",
    "        optimizer.step()  # 更新权重\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "print(\"Finished Training\")\n",
    "\n",
    "# 测试模型\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)  # 前向传播\n",
    "        _, predicted = torch.max(outputs.data, 1)  # 找到最大概率的类别\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the test set: {accuracy}%\")"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 400]' is invalid for input of size 16384",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 55\u001B[0m\n\u001B[0;32m     52\u001B[0m inputs, labels \u001B[38;5;241m=\u001B[39m data\n\u001B[0;32m     53\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()  \u001B[38;5;66;03m# 清零梯度\u001B[39;00m\n\u001B[1;32m---> 55\u001B[0m outputs \u001B[38;5;241m=\u001B[39m net(inputs)  \u001B[38;5;66;03m# 前向传播\u001B[39;00m\n\u001B[0;32m     56\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)  \u001B[38;5;66;03m# 计算损失\u001B[39;00m\n\u001B[0;32m     57\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()  \u001B[38;5;66;03m# 反向传播，计算梯度\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\pythonProject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\pythonProject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[4], line 25\u001B[0m, in \u001B[0;36mLeNet5.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     23\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool1(torch\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv1(x)))\n\u001B[0;32m     24\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpool2(torch\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(x)))\n\u001B[1;32m---> 25\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m16\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m5\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m5\u001B[39m)      \u001B[38;5;66;03m# 展平为一维\u001B[39;00m\n\u001B[0;32m     26\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc1(x))\n\u001B[0;32m     27\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc2(x))\n",
      "\u001B[1;31mRuntimeError\u001B[0m: shape '[-1, 400]' is invalid for input of size 16384"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "9d89723a0f087bc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T14:27:39.170716Z",
     "start_time": "2024-04-29T14:27:39.167323Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
