{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71c55dc5a09277b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Using ZhipuAI GLM-4 in Langchain\n",
    "\n",
    "**This tutorial is available in English and is attached below the Chinese explanation**\n",
    "\n",
    "æœ¬ä»£ç ï¼Œæˆ‘ä»¬å°†å¸¦é¢†å¤§å®¶å¦‚ä½•ä½¿ç”¨ Langchain æ¥è°ƒç”¨ ZhipuAI çš„ GLM-4 æ¨¡å‹ã€‚\n",
    "ä½ å°†åœ¨æœ¬ç« èŠ‚å­¦ä¹ åˆ°å¦‚ä½•ä½¿ç”¨ Langchain çš„ `ChatZhipuAI` ç±»æ¥è°ƒç”¨ ZhipuAI çš„ GLM-4 æ¨¡å‹ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨ `ChatZhipuAI` ç±»æ¥å®ç°ç±»ä¼¼ `ChatOpenAI` çš„æ–¹æ³•æ¥è¿›è¡Œè°ƒç”¨ã€‚\n",
    "\n",
    "In this notebook, I will show you how to use Langchain to call ZhipuAI's GLM-4 model.\n",
    "In this chapter, you will learn how to use Langchain's `ChatZhipuAI` class to call ZhipuAI's GLM-4 model, and how to use the `ChatZhipuAI` class to implement methods similar to `ChatOpenAI` to make calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d50b54cbc991843",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1. Install Langchain\n",
    "\n",
    "ç”±äºæœ¬æ•™ç¨‹éœ€è¦ä½¿ç”¨ Langchainè¿›è¡Œè°ƒç”¨ï¼Œå› æ­¤æˆ‘ä»¬é¦–å…ˆéœ€è¦å®‰è£… Langchain å’Œ å¯¹åº”çš„ä¾èµ–åŒ…ã€‚ è¯·ç¡®ä¿ langchain_community çš„ç‰ˆæœ¬åœ¨ 0.0.32 ä»¥ä¸Šã€‚\n",
    "\n",
    "Since this tutorial requires Langchain to be called, you first need to install Langchain and the corresponding dependency packages. Make sure that the version of langchain_community is above 0.0.32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56028f01ac7638e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:39:30.680433Z",
     "start_time": "2024-04-27T10:39:08.720963Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# ! pip install pydantic\n",
    "# ! pip install --upgrade langchain_core\n",
    "# ! pip install --upgrade langchainhub httpx_sse -i http://mirrors.aliyun.com/pypi/simple/\n",
    "# ! pip install --upgrade langchain langchain_community -i https://pypi.mirrors.ustc.edu.cn/simple/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e70f847aa90565",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "ç°åœ¨ï¼Œè®¾ç½®å¥½ ZhipuAI çš„ API Keyï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨ ZhipuAI çš„ GLM-4 æ¨¡å‹äº†ã€‚\n",
    "Now, you need to set up ZhipuAIâ€™s API Key so that you can use ZhipuAIâ€™s GLM-4 model.\n",
    "> å¦‚æœä½ éœ€è¦ä½¿ç”¨æœ¬ç« èŠ‚çš„ç¬¬ 4 éƒ¨åˆ†æ•™ç¨‹ï¼Œä½ éœ€è¦å¡«å†™ TAVILY_API_KEYï¼Œè¯¥å·¥å…·ç”¨äºæ‰§è¡Œ Langchain çš„ å·¥å…·è°ƒç”¨ã€‚\n",
    "If you need to use the fourth part of the tutorial in this chapter, you need to fill in TAVILY_API_KEY, which is used to execute Langchainâ€™s tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c8299e0683b8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:39:49.201234Z",
     "start_time": "2024-04-27T10:39:49.196725Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"ZHIPUAI_API_KEY\"] = \"7cc2d454b5b31371f5c6c990fddc7636.EPXYYOmeKYWvDEqW\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b191a56f0f6ec",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 2. Use the method of `ChatZhipuAI` class to call ZhipuAIâ€™s GLM-4 model\n",
    "\n",
    "å’Œ `ChatOpenAI` ç±»ä¸€æ ·ï¼Œ`ChatZhipuAI` ç±»ä¹Ÿæ˜¯ä¸€ä¸ªå¯ä»¥è°ƒç”¨ ZhipuAI çš„ GLM-4 æ¨¡å‹çš„ç±»ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `ChatZhipuAI`æ¥æ›¿æ¢ `ChatOpenAI` ç±»ï¼Œç›´æ¥æ— ç¼å¯¹æ¥åˆ°è‡ªå·±çš„é¡¹ç›®ä¸­ã€‚è¿™é‡Œå±•ç°äº†ä¸€ä¸ªæœ€åŸºæœ¬çš„è°ƒç”¨æ–¹æ³•ã€‚\n",
    "\n",
    "Like the `ChatOpenAI` class, the `ChatZhipuAI` class is also a class that can call ZhipuAI's GLM-4 model. you can use `ChatZhipuAI` to replace the `ChatOpenAI` class and directly and seamlessly connect it to our own projects. Here is a basic calling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e74dc43ab33e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:42:29.508164Z",
     "start_time": "2024-04-27T10:42:24.491311Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initially, there were 9 birds on the tree. After the hunter shot and killed one, there would be 8 birds remaining on the tree. However, if you're asking for the total number of birds including the one that was shot, then there were still 9 birds in existence, but only 8 of them remained on the tree. The question is a bit tricky because it depends on whether you're asking about the number left on the tree or the total number of birds.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    AIMessage(\n",
    "        content=\"Hi,\"\n",
    "    ),\n",
    "    SystemMessage(\n",
    "        content=\"You are a smart assistant, please reply to me smartly.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"There were 9 birds on the tree. The hunter shot and killed one. How many birds were there?\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "llm = ChatZhipuAI(\n",
    "    temperature=0.95,\n",
    "    model=\"glm-4\"\n",
    ")\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dd61f74ceb10f5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 3. Use Langchain to call your own fine-tuned model.\n",
    "\n",
    "ZhipuAI å·²ç»æ”¯æŒä½¿ç”¨ Langchain è°ƒç”¨å¾®è°ƒçš„ ChatGLM ç³»åˆ—æ¨¡å‹ï¼Œå¦‚æœä½ æƒ³å­¦ä¹ å¦‚ä½•å¾®è°ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹[å¾®è°ƒæ•™ç¨‹](../finetune/glm_lora_finetune_pysdk.ipynb) æ¥å¾®è°ƒè‡ªå·±çš„æ¨¡å‹ã€‚\n",
    "\n",
    "ZhipuAI already supports using Langchain to call the fine-tuned ChatGLM series models. If you want to learn how to fine-tune the model, please view the [Fine-tuning Tutorial](../finetune/glm_lora_finetune_pysdk.ipynb) to fine-tune your own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6f5773c7a88debb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:44:42.895138Z",
     "start_time": "2024-04-27T10:44:28.512830Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='æ ¹æ®æ‚¨æä¾›çš„ä¿¡æ¯ï¼Œå¦‚æœæƒ³è¦æ‰“é€ ä¸€ç§ç®€çº¦è‹±ä¼¦é£æ ¼çš„è£¤è£…æ­é…ï¼Œå¯ä»¥éµå¾ªä»¥ä¸‹å»ºè®®ï¼š\\n\\n### è£¤å­é€‰æ‹©ï¼š\\n1. **è‰²å½©**ï¼šé€‰æ‹©çº¯è‰²ã€ä¸­æ€§è‰²è°ƒçš„è£¤å­ï¼Œå¦‚æ·±è“ã€ç°è‰²æˆ–æ˜¯ç»å…¸çš„ç™½è‰²ï¼Œè¿™äº›éƒ½æ˜¯è‹±ä¼¦é£æ ¼ä¸­å¸¸è§çš„é¢œè‰²ã€‚\\n2. **æ¬¾å¼**ï¼šç®€çº¦çš„ç›´ç­’è£¤æˆ–ä¼‘é—²è£¤èƒ½å¤Ÿä¿®é¥°è…¿å‹ï¼ŒåŒæ—¶ä¿æŒæ•´ä½“çš„ç®€æ´æ„Ÿã€‚å®½æ¾çš„è£¤å‹ä¸ä»…èˆ’é€‚ï¼Œè¿˜èƒ½è¥é€ å‡ºå¤å¤çš„æ°›å›´ã€‚\\n\\n### æ­é…å»ºè®®ï¼š\\n1. **ä¸Šè¡£**ï¼šå¯ä»¥æ­é…çº¯è‰²ç³»çš„é’ˆç»‡è¡«æˆ–æ˜¯æœ‰è´¨æ„Ÿçš„è¡¬è¡«ã€‚ä¾‹å¦‚ï¼Œä¸€ä»¶ç²‰è‰²çš„è¡¬è¡«æ­é…ç°è‰²ç›´ç­’è£¤ï¼Œæ—¢ç”œç¾åˆå¹²ç»ƒã€‚\\n   \\n2. **å¤–å¥—**ï¼šå¯ä»¥é€‰æ‹©å¤§è¡£æˆ–æ˜¯é£è¡£ä½œä¸ºå¤–å¥—ï¼Œç‰¹åˆ«æ˜¯ç®€çº¦çº¯è‰²çš„å¤§è¡£ï¼Œå®ƒèƒ½å¤Ÿæä¾›ä¸€ç§ç®€æ´å¤§æ–¹çš„æ„Ÿè§‰ï¼ŒåŒæ—¶ä¹Ÿèƒ½å¾ˆå¥½åœ°èå…¥è‹±ä¼¦é£æ ¼ä¸­ã€‚\\n\\n3. **é…é¥°**ï¼šç®€çº¦çš„é…é¥°å¦‚å°å·§çš„åŒ…åŒ…æˆ–æ˜¯é¸­èˆŒå¸½å¯ä»¥å¢åŠ å¤å¤æ„Ÿï¼Œä½†è¦æ³¨æ„ä¸è¦è¿‡å¤šï¼Œä»¥å…ç ´åæ•´ä½“çš„ç®€çº¦é£æ ¼ã€‚\\n\\n### å®Œæ•´æ­é…ç¤ºä¾‹ï¼š\\n- **æ—¥å¸¸ä¼‘é—²**ï¼šç™½è‰²å®½æ¾ç›´ç­’è£¤æ­é…æ·±è“è‰²åœ†é¢†é’ˆç»‡è¡«ï¼Œå¤–æ­ä¸€ä»¶ç®€çº¦çš„ç°è‰²é£è¡£ï¼Œå†åŠ ä¸Šä¸€åŒç»å…¸çš„å°ç™½é‹ï¼Œæ—¢èˆ’é€‚åˆä¸å¤±è‹±ä¼¦é£æ ¼ã€‚\\n- **åŠå…¬å®¤èŒåœº**ï¼šæ·±è‰²ç›´ç­’è£¤æ­é…æµ…è‰²è¡¬è¡«ï¼Œå¤–æ­ä¸€ä»¶ç®€çº¦å‰ªè£çš„è¥¿è£…å¤–å¥—ï¼Œæ—¢æ­£å¼åˆå¸¦æœ‰å¤å¤çš„è‹±ä¼¦æ°”æ¯ã€‚\\n\\né€šè¿‡è¿™æ ·çš„æ­é…ï¼Œå³ä½¿æ˜¯å°ä¸ªå­å¥³æ€§ä¹Ÿèƒ½è½»æ¾é©¾é©­ç®€çº¦çš„è‹±ä¼¦é£æ ¼ï¼Œæ—¢å¤§æ–¹é«˜çº§ï¼Œåˆèƒ½å±•ç°ä¸ªäººçš„ç‹¬ç‰¹é­…åŠ›ã€‚', response_metadata={'token_usage': {'completion_tokens': 331, 'prompt_tokens': 946, 'total_tokens': 1277}, 'model_name': 'glm-4', 'finish_reason': 'stop'}, id='run-b20b4d72-39ae-4b3c-842d-be16c97e0b33-0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"ç±»å‹#è£¤*é£æ ¼#è‹±ä¼¦*é£æ ¼#ç®€çº¦\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "fine_tuned_model = ChatZhipuAI(\n",
    "    temperature=0.2, model=\"glm-4\"\n",
    ")\n",
    "\n",
    "fine_tuned_model(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d812902132ada30e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 4. ä½¿ç”¨ Langchain æ¥å®Œæˆä¸€ä¸ªç®€å•çš„ Function Call è°ƒç”¨\n",
    "\n",
    "å¾—ç›Šäº ZhipuAI ä¹Ÿå…·æœ‰æå¼ºçš„ å·¥å…·è°ƒç”¨èƒ½åŠ›ï¼Œä½ å¯ä»¥ä½¿ç”¨å®ƒæ¥å®Œæˆ Langchainä¸­çš„ `Agent` ç±»çš„åŠŸèƒ½ï¼Œè¿™é‡Œæˆ‘ä»¬å±•ç¤ºäº†ä¸€ä¸ªç®€å•çš„è°ƒç”¨æ–¹æ³•ã€‚\n",
    "\n",
    "æˆ‘å‚è€ƒ [Langchain å®˜æ–¹æ•™ç¨‹](https://python.langchain.com/docs/modules/agents/agent_types/openai_functions_agent) çš„æ–¹æ¡ˆï¼Œå¹¶ä»…ä»…å°† `ChatOpenAI`æ›¿æ¢ä¸º`ChatZhipuAI`ï¼Œé™¤äº†æ¨¡å‹åŠ è½½æ–¹å¼ï¼Œåœ¨ Agent ä»£ç ä¸­å®Œå…¨ä¸ç”¨è¿›è¡Œä»»ä½•ä»£ç ä¿®æ”¹ã€‚\n",
    "\n",
    "Thanks to ZhipuAI's strong tool calling capabilities, you can use it to complete the functions of the `Agent` class in Langchain. Here we show a simple calling method.\n",
    "\n",
    "I refer to the solution of [Langchain official tutorial](https://python.langchain.com/docs/modules/agents/agent_types/openai_functions_agent) and just replace `ChatOpenAI` with `ChatZhipuAI`. Except for the model loading method, in Agent There is absolutely no need to make any code modifications in the code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ade454081305502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:44:59.462801Z",
     "start_time": "2024-04-27T10:44:48.329050Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_json_chat_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tools = [TavilySearchResults(max_results=1)]\n",
    "prompt = hub.pull(\"hwchase17/react-chat-json\")\n",
    "agent = create_json_chat_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True, handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd4dd9dd81c448",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "æ¥ç€ï¼Œæˆ‘ä»¬æ‰§è¡Œè¿™ä¸ªä»£ç ï¼Œå°±å¯ä»¥è·å¾—æ­£ç¡®çš„ç­”æ¡ˆã€‚è§‚å¯Ÿåˆ°æ™ºè°±AI èƒ½ç›´æ¥æ— ç¼çš„ä½¿ç”¨ Langchain çš„ `Agent` ç±»çš„åŠŸèƒ½ã€‚\n",
    "\n",
    "Then, we execute this code and get the correct answer. It is observed that Zhipu AI can directly and seamlessly use the functions of Langchain's `Agent` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5bc6d699ea277a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:45:11.731886Z",
     "start_time": "2024-04-27T10:45:01.546666Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"tavily_search_results_json\",\n",
      "    \"action_input\": \"LangChain\"\n",
      "}\n",
      "```\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.langchain.com/', 'content': 'Join Discord\\nContribute on GitHub\\n5.3M\\nMonthly Downloads\\n67k\\nGithub Stars\\n1800+\\nContributors\\n34k+\\nApps Powered\\nReady to build?\\nGo To Docs\\nGo To Docs\\nGo To Docs\\nContact Sales\\nContact Sales\\nContact Sales\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter\\nProducts and use-cases\\nLangChain\\nLangSmith\\nRetrieval\\nAgents\\nInspiration\\nCode\\nGitHub\\nLangChain Hub\\nPython Docs\\nJS/TS Docs\\nSocial\\nTwitter\\nDiscord\\nBlog\\nLinkedIn\\nYouTube\\nTerms of Service\\nSign up for our newsletter Chatbots\\nQ&A Over Docs\\nSummarization\\nCopilots\\nWorkflow Automation\\nDocument Analysis\\nCustom Search\\nHarness the powerâ€“and wrangle the complexityâ€“ of LLMs\\nGet from proof-of-concept to production on one platform\\nRely on a set of tools built especially for non-deterministic models\\nLeverage new cognitive architectures and battle-tested orchestration\\nThanks to our contributors and partners for making LangChain awesome\\nWhen you build with LangChain, you build alongside a community of developers advancing the frontier of whatâ€™s possible with LLMs.\\n ğŸ¦œğŸ”— LangChain\\nLangSmith\\nLangServe\\nAgents\\nRetrieval\\nEvaluation\\nBlog\\nDocs\\nğŸ¦œğŸ”— LangChain\\nğŸ¦œğŸ”— LangChain\\nLangChain Expression Language makes it easy to create custom chains.\\n Go To Docs\\nGo To Docs\\nGo To Docs\\nContact Sales\\nglobal corporations, STARTUPS, and TINKERERS build with LangChain\\nglobal corporations, STARTUPS, and TINKERERS build with LangChain\\nglobal corporations, STARTUPS, and TINKERERS build with LangChain\\nA complete set of powerful building blocks\\nA complete set of powerful building blocks\\n Try it out here\\nGet your LLM application from prototype to production\\nGet your LLM application from prototype to production\\nBuild context-aware, reasoning applications with LangChainâ€™s flexible abstractions and AI-first toolkit.\\n'}]\u001b[0m\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"LangChain is a platform that allows developers to build applications using large language models. It provides a set of tools and resources to help with the development process, from prototyping to production. LangChain is used by global corporations, startups, and individual developers to create context-aware, reasoning applications with the help of its flexible abstractions and AI-first toolkit.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is LangChain?',\n",
       " 'output': 'LangChain is a platform that allows developers to build applications using large language models. It provides a set of tools and resources to help with the development process, from prototyping to production. LangChain is used by global corporations, startups, and individual developers to create context-aware, reasoning applications with the help of its flexible abstractions and AI-first toolkit.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"what is LangChain?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f3b64b6ef3fd40",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "é€šè¿‡æœ¬æ•™ç¨‹ï¼Œæ‚¨å°†èƒ½å¿«é€Ÿçš„åˆ‡æ¢ `Langchain` çš„æ¨¡å‹è¯»å…¥ï¼Œå°†æ¨¡å‹åˆ‡æ¢ä¸º ZhipuAI çš„ GLM-4 ç³»åˆ—æ¨¡å‹ã€‚æœ¬ä»£ç åªæ˜¯åŸºç¡€æ•™ç¨‹ï¼Œæˆ‘å°†äºä¹‹åæ¨å‡ºæ›´å¤šè¿›é˜¶çš„ä½¿ç”¨ GLM-4 ç³»åˆ—æ¨¡å‹å’Œ Langchain çš„é…åˆä½œå“ã€‚\n",
    "\n",
    "Through this tutorial, you will be able to quickly switch to `Langchain` model reading and switch the model to ZhipuAI's GLM-4 series model. This code is just a basic tutorial. I will launch more advanced works using GLM-4 series models and Langchain in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9ec1a9ddd16a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
