{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 使用 Langchain 和 GLM 完成简单的简历信息抽取任务。\n",
    "\n",
    "**This tutorial is Only in Chinese explanation**\n",
    "\n",
    "本代码，我将使用 Langchain 配合 GLM-4 完成 Word 文档的简历信息抽取任务。\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9c7735c37bd4a71"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. 配置相关环境\n",
    "由于需要安装部分依赖，这里我们需要安装必要的依赖，如果你已经安装了这些依赖，你可以跳过这个步骤。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71f6db85940dd9ad"
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install langchain unstructured python-docx  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T11:02:29.369839Z",
     "start_time": "2024-04-27T11:01:44.224941Z"
    }
   },
   "id": "4fa261f2679ba7e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: langchain in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (0.1.16)\n",
      "Collecting unstructured\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/11/70/e227b79112c72b1536cf61ca9a9affef6c1895cd38ec335b69eb8a1389f4/unstructured-0.13.4-py3-none-any.whl (1.9 MB)\n",
      "     ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.1/1.9 MB 1.3 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 0.1/1.9 MB 1.2 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 0.2/1.9 MB 1.5 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 0.3/1.9 MB 1.6 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 0.5/1.9 MB 1.9 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 0.6/1.9 MB 2.1 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 0.9/1.9 MB 2.6 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.2/1.9 MB 3.1 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 1.4/1.9 MB 3.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.9/1.9 MB 4.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.9/1.9 MB 3.9 MB/s eta 0:00:00\n",
      "Collecting python-docx\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/5f/d8/6948f7ac00edf74bfa52b3c5e3073df20284bec1db466d13e668fe991707/python_docx-1.1.0-py3-none-any.whl (239 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from langchain) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from langchain) (0.0.34)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from langchain) (0.1.46)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from langchain) (0.1.51)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from langchain) (2.7.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Collecting chardet (from unstructured)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "     ---------------------------------------- 0.0/199.4 kB ? eta -:--:--\n",
      "     -------------------------------------- 199.4/199.4 kB 6.1 MB/s eta 0:00:00\n",
      "Collecting filetype (from unstructured)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/18/79/1b8fa1bb3568781e84c9200f951c735f3f157429f44be0495da55894d620/filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6c/73/9f872cb81fc5c3bb48f7227872c28975f998f3e7c2b1c16e95e6432bbb90/python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Collecting lxml (from unstructured)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/df/c5/8b05e69685b48cf11b596fbdd466f76cb3c1e3efe0361d8be0edb9df0325/lxml-5.2.1-cp311-cp311-win_amd64.whl (3.8 MB)\n",
      "     ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.5/3.8 MB 9.8 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 0.9/3.8 MB 9.5 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 1.5/3.8 MB 10.6 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 2.2/3.8 MB 11.4 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 3.0/3.8 MB 12.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 3.7/3.8 MB 13.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.8/3.8 MB 12.2 MB/s eta 0:00:00\n",
      "Collecting nltk (from unstructured)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a6/0a/0d20d2c0f16be91b9fa32a77b76c60f9baf6eba419e5ef5deca17af9c582/nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     --------------------------- ------------ 1.0/1.5 MB 22.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 19.0 MB/s eta 0:00:00\n",
      "Collecting tabulate (from unstructured)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/40/44/4a5f08c96eb108af5cb50b41f76142f0afa346dfa99d5296fe7202a11854/tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from unstructured) (4.12.2)\n",
      "Collecting emoji (from unstructured)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bd/48/508a980e9c9f12dbc2e45e57f027abdd92320e5be37c5c551588a86acb48/emoji-2.11.1-py2.py3-none-any.whl (433 kB)\n",
      "     ---------------------------------------- 0.0/433.8 kB ? eta -:--:--\n",
      "     ------------------------------------- 433.8/433.8 kB 13.7 MB/s eta 0:00:00\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/01/62/2fed44ba10fe805345fb0e9c46c7f8dcdaf1bffd642f051fcc3db9bf55d8/python_iso639-2024.2.7-py3-none-any.whl (274 kB)\n",
      "     ---------------------------------------- 0.0/274.7 kB ? eta -:--:--\n",
      "     ------------------------------------- 274.7/274.7 kB 17.6 MB/s eta 0:00:00\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0e/72/a3add0e4eec4eb9e2569554f7c70f4a3c27712f40e3284d483e88094cc0e/langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ------------------------------- ----- 829.4/981.5 kB 17.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- 981.5/981.5 kB 15.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/59/0c/57ee517b3f4acc7719f7c6bdcb31d7e64806060d456ce64de29741f1a58a/rapidfuzz-3.8.1-cp311-cp311-win_amd64.whl (1.7 MB)\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 0.2/1.7 MB 14.1 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 0.8/1.7 MB 10.4 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 1.5/1.7 MB 11.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.7/1.7 MB 10.5 MB/s eta 0:00:00\n",
      "Collecting backoff (from unstructured)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/df/73/b6e24bd22e6720ca8ee9a85a0c4a2971af8497d8f3193fa05390cbd46e09/backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from unstructured) (4.9.0)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b0/bc/c74937363c2657a77e4c4e105b7a004203ad53f128b5caf5dbb9dc9458d1/unstructured_client-0.22.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from unstructured) (1.14.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.42->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: six in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from langdetect->unstructured) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from nltk->unstructured) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from nltk->unstructured) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from nltk->unstructured) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from nltk->unstructured) (4.65.2)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/57/ec/80c8d48ac8b1741d5b963797b7c0c869335619e13d4744ca2f67fc11c6fc/charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl (99 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/91/ca/7219b838086086972e662c19e908694bdc6744537fb41b70392501b8b5e4/dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Collecting deepdiff>=6.0 (from unstructured-client->unstructured)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/18/e6/d27d37dc55dbf40cdbd665aa52844b065ac760c9a02a02265f97ea7a4256/deepdiff-7.0.1-py3-none-any.whl (80 kB)\n",
      "     ---------------------------------------- 0.0/80.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 80.8/80.8 kB 4.4 MB/s eta 0:00:00\n",
      "Collecting jsonpath-python>=1.0.6 (from unstructured-client->unstructured)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/16/8a/d63959f4eff03893a00e6e63592e3a9f15b9266ed8e0275ab77f8c7dbc94/jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c9/d1/450b19bbdbb2c802f554312c62ce2a2c0d8744fe14735bc70ad2803578c7/pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
      "     ---------------------------------------- 0.0/290.4 kB ? eta -:--:--\n",
      "     -------------------------------------- 290.4/290.4 kB 9.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from unstructured-client->unstructured) (2.8.2)\n",
      "Collecting ordered-set<4.2.0,>=4.1.0 (from deepdiff>=6.0->unstructured-client->unstructured)\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/33/55/af02708f230eb77084a299d7b08175cff006dea4f2721074b92cdb0296c0/ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\33398\\.conda\\envs\\pythonproject\\lib\\site-packages (from click->nltk->unstructured) (0.4.6)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993255 sha256=4dabac2515693e54c2c6b68c0f9f162c76473d9c39a728da2cd1a23e294d37de\n",
      "  Stored in directory: c:\\users\\33398\\appdata\\local\\pip\\cache\\wheels\\a8\\77\\58\\91b7f1c32087f5ceba0c8376bb08f5982fe189fc656e6632b0\n",
      "Successfully built langdetect\n",
      "Installing collected packages: filetype, tabulate, rapidfuzz, python-magic, python-iso639, pypdf, ordered-set, lxml, langdetect, jsonpath-python, emoji, charset-normalizer, chardet, backoff, python-docx, nltk, deepdiff, dataclasses-json, unstructured-client, unstructured\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.0.4\n",
      "    Uninstalling charset-normalizer-2.0.4:\n",
      "      Successfully uninstalled charset-normalizer-2.0.4\n",
      "  Attempting uninstall: dataclasses-json\n",
      "    Found existing installation: dataclasses-json 0.5.14\n",
      "    Uninstalling dataclasses-json-0.5.14:\n",
      "      Successfully uninstalled dataclasses-json-0.5.14\n",
      "Successfully installed backoff-2.2.1 chardet-5.2.0 charset-normalizer-3.3.2 dataclasses-json-0.6.4 deepdiff-7.0.1 emoji-2.11.1 filetype-1.2.0 jsonpath-python-1.0.6 langdetect-1.0.9 lxml-5.2.1 nltk-3.8.1 ordered-set-4.1.0 pypdf-4.2.0 python-docx-1.1.0 python-iso639-2024.2.7 python-magic-0.4.27 rapidfuzz-3.8.1 tabulate-0.9.0 unstructured-0.13.4 unstructured-client-0.22.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "接着，我们需要将我们的 API_KEY 配置到环境变量中，用于调用 GLM-4 模型。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "741ecbd0ae7b3148"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"ZHIPUAI_API_KEY\"] = \"7cc2d454b5b31371f5c6c990fddc7636.EPXYYOmeKYWvDEqW\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T13:52:57.742761Z",
     "start_time": "2024-02-02T13:52:57.740017Z"
    }
   },
   "id": "5f982f839d2340d3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. 读取简历文档\n",
    "\n",
    "我们需要将简历的文档用 Langchain 的 UnstructuredWordDocumentLoader 读入，并填充到我们的模板中。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd69981c5a6fb246"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredWordDocumentLoader\n",
    "\n",
    "loader = UnstructuredWordDocumentLoader(\"data/resume.docx\")\n",
    "data = loader.load()"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-02T13:52:57.777970Z",
     "start_time": "2024-02-02T13:52:57.743554Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "设定好模板，这个模板将会作为我们的系统提示词。我们将使用 Langchain 的 ChatPromptTemplate 来构建这个模板。其中，{resume} 将会被我们的简历内容填充。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90f6dca3b6fec516"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from langchain_core.prompts import SystemMessagePromptTemplate\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "你是 ZhipuAI 的 人事资源管理部门的优秀员工，现在我需要你帮我阅读简历并筛选出合适的人才，请你基于我提供的简历，对简历进行细节的分析，抓取相关的资料并回答我提出的问题。\n",
    "现在，我将会将简历以文字的形式给你提供，具体内容如下:\n",
    "\n",
    "<resume>\n",
    "{resume}\n",
    "</resume>\n",
    "\n",
    "请你根据我的简历，开始回答我的问题吧。请注意我的提问的内容和我需要你回答的格式，我们开始吧：\n",
    "\"\"\"\n",
    "\n",
    "question_prompt = [\n",
    "    \"候选人读过哪些大学？\",\n",
    "    # \"请帮我提取候选人简历中的关键信息，用JSON格式返回给我，我需要的字段是：姓名、性别、年龄、学历、工作年限、工作经历、项目经历、技能、个人优势、个人缺点、兴趣爱好；简历中没有提到的字段也要输出，但字段值为空。json的key可以使用中文，value的长度不要超过100个字符，如果字段值太长，请对内容进行总结摘要再输出。例如工作经历可以只保留公司名称和职位，工作经历和项目经历可以只保留项目名称和项目描述\",\n",
    "    # \"你怎么评价这个候选人，从他现有的资历、技术能力、工作态度、发展潜力进行分析。我们公司目前想招聘一个3-5年工作经验有一定的发展潜力的员工，请结合对候选人的分析和我的招聘需求判断我是否应该给他面试机会？\"\n",
    "]\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "    ]\n",
    ")\n",
    "messages = chat_template.format_messages(resume=data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T13:52:57.783016Z",
     "start_time": "2024-02-02T13:52:57.781318Z"
    }
   },
   "id": "c500b35994e14ff2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "接着，我们就可以调用 GLM-4 模型，通过模型对简历进行抓取和提取关键信息，获得有效的内容和答案。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e01263d1a189281f"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "候选人李明浩读过的大学有：\n",
      "\n",
      "1. 清华大学，专业是计算机科学与技术。\n",
      "2. 北京邮电大学，专业是信息技术。\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "\n",
    "for question in question_prompt:\n",
    "    messages = chat_template.format_messages(resume=data)\n",
    "    messages.append(\n",
    "        HumanMessage(\n",
    "            content=question\n",
    "        )\n",
    "    )\n",
    "    llm = ChatZhipuAI(\n",
    "        temperature=0.01,\n",
    "        model=\"glm-4\",\n",
    "        max_tokens=8192,\n",
    "        stream=False,\n",
    "    )\n",
    "    messages.append(\n",
    "        AIMessage(\n",
    "            content=llm(messages).content\n",
    "        )\n",
    "    )\n",
    "    print(messages[-1].content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-02T13:53:00.080689Z",
     "start_time": "2024-02-02T13:52:57.785262Z"
    }
   },
   "id": "1f6fc2837b9d98b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. 结果分析\n",
    "\n",
    "通过大模型，我们可以顺利的抽取出简历中的关键信息，包括教育背景、工作经历等。这样，我们就可以通过简单的代码，完成简历信息的抽取任务。\n",
    "这是一个开放性的demo，意味着你可以自己选择其他任务来接着完成这个场景的研究。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a78cbd80584dfa28"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
